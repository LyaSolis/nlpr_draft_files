{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3_pretraining_exBERT.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyPzI6rBeZE+nWM9knVJQDWv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["### Pre-training with BERT"],"metadata":{"id":"URLWQqrqgzh4"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"yqnTtgv_gujL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648535593194,"user_tz":-60,"elapsed":15635,"user":{"displayName":"Lya Solis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0zQkkPA02m_TCbUFh15I5DgeImYkaFOwSePgp=s64","userId":"00474828135331575492"}},"outputId":"db996ba2-1ff6-4e6f-bf07-729e8368667b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import shutil\n","shutil.copytree(\"/content/drive/MyDrive/GitHub/exBERT/exBERT\", \"./exBERT\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"BKj02H6MNTOC","executionInfo":{"status":"ok","timestamp":1648535616640,"user_tz":-60,"elapsed":8883,"user":{"displayName":"Lya Solis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0zQkkPA02m_TCbUFh15I5DgeImYkaFOwSePgp=s64","userId":"00474828135331575492"}},"outputId":"7ffff777-9d28-4329-e453-8b581c67772b"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'./exBERT'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["!pip install transformers\n","!pip install tokenizers"],"metadata":{"id":"beeWTOuRgzLR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648535631292,"user_tz":-60,"elapsed":13069,"user":{"displayName":"Lya Solis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0zQkkPA02m_TCbUFh15I5DgeImYkaFOwSePgp=s64","userId":"00474828135331575492"}},"outputId":"564295ba-8501-4e3d-d763-b51c11f78ffd"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 5.3 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 57.1 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 58.0 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,>=0.11.1\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 47.6 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0\n","Requirement already satisfied: tokenizers in /usr/local/lib/python3.7/dist-packages (0.11.6)\n"]}]},{"cell_type":"code","source":["!pip install boto3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nEtVVtqKQydv","executionInfo":{"status":"ok","timestamp":1648535640613,"user_tz":-60,"elapsed":9330,"user":{"displayName":"Lya Solis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0zQkkPA02m_TCbUFh15I5DgeImYkaFOwSePgp=s64","userId":"00474828135331575492"}},"outputId":"05c63f11-13c8-45f5-c865-41605dedcb2d"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting boto3\n","  Downloading boto3-1.21.28-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 5.1 MB/s \n","\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n","  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 6.9 MB/s \n","\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n","  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n","Collecting botocore<1.25.0,>=1.24.28\n","  Downloading botocore-1.24.28-py3-none-any.whl (8.6 MB)\n","\u001b[K     |████████████████████████████████| 8.6 MB 40.8 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.28->boto3) (2.8.2)\n","Collecting urllib3<1.27,>=1.25.4\n","  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 38.6 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.28->boto3) (1.15.0)\n","Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.9 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed boto3-1.21.28 botocore-1.24.28 jmespath-1.0.0 s3transfer-0.5.2 urllib3-1.26.9\n"]}]},{"cell_type":"code","source":["!pip install datasets git+https://github.com/huggingface/transformers/\n","!pip install torch torchvision tensorflow\n","!pip install pytorch-pretrained-bert pandas"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tf0USlQyRK5J","executionInfo":{"status":"ok","timestamp":1648535698316,"user_tz":-60,"elapsed":43758,"user":{"displayName":"Lya Solis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0zQkkPA02m_TCbUFh15I5DgeImYkaFOwSePgp=s64","userId":"00474828135331575492"}},"outputId":"298a204c-5d10-4247-c416-428dc7cd5f76"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/huggingface/transformers/\n","  Cloning https://github.com/huggingface/transformers/ to /tmp/pip-req-build-g4dkajd8\n","  Running command git clone -q https://github.com/huggingface/transformers/ /tmp/pip-req-build-g4dkajd8\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Collecting datasets\n","  Downloading datasets-2.0.0-py3-none-any.whl (325 kB)\n","\u001b[K     |████████████████████████████████| 325 kB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (0.4.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (1.21.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (3.6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (2019.12.20)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (21.3)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (0.0.49)\n","Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (0.11.6)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (4.63.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (4.11.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0.dev0) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.18.0.dev0) (3.0.7)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Collecting fsspec[http]>=2021.05.0\n","  Downloading fsspec-2022.2.0-py3-none-any.whl (134 kB)\n","\u001b[K     |████████████████████████████████| 134 kB 49.2 MB/s \n","\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 58.9 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Collecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 56.4 MB/s \n","\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.18.0.dev0) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.18.0.dev0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.18.0.dev0) (3.0.4)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 59.6 MB/s \n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 37.8 MB/s \n","\u001b[?25hCollecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 62.7 MB/s \n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 2.9 MB/s \n","\u001b[?25hCollecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Collecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.18.0.dev0) (3.7.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.18.0.dev0) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.18.0.dev0) (7.1.2)\n","Building wheels for collected packages: transformers\n","  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transformers: filename=transformers-4.18.0.dev0-py3-none-any.whl size=3946315 sha256=e10aaf585072e8dfc689148219b22a51ce67f603db0b26abc7aad8e25553e7f2\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-5r09trwv/wheels/fb/1b/91/0fcf504c386d427d65bbaf663eadf8e18cbf9795394ed7050d\n","Successfully built transformers\n","Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xxhash, responses, transformers, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.26.9\n","    Uninstalling urllib3-1.26.9:\n","      Successfully uninstalled urllib3-1.26.9\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.17.0\n","    Uninstalling transformers-4.17.0:\n","      Successfully uninstalled transformers-4.17.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.0.0 frozenlist-1.3.0 fsspec-2022.2.0 multidict-6.0.2 responses-0.18.0 transformers-4.18.0.dev0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.5)\n","Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.24.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n","Collecting tf-estimator-nightly==2.8.0.dev2021122109\n","  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n","\u001b[K     |████████████████████████████████| 462 kB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.44.0)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (13.0.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n","Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.7.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.25.11)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n","Installing collected packages: tf-estimator-nightly\n","Successfully installed tf-estimator-nightly-2.8.0.dev2021122109\n","Collecting pytorch-pretrained-bert\n","  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n","\u001b[K     |████████████████████████████████| 123 kB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.10.0+cu111)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.21.5)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.21.28)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (4.63.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.10.0.2)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n","Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (1.0.0)\n","Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (0.5.2)\n","Requirement already satisfied: botocore<1.25.0,>=1.24.28 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (1.24.28)\n","Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.28->boto3->pytorch-pretrained-bert) (1.25.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n","Installing collected packages: pytorch-pretrained-bert\n","Successfully installed pytorch-pretrained-bert-0.6.2\n"]}]},{"cell_type":"code","source":["!ls /content/drive/MyDrive/GitHub/exBERT/PubMED_train_files/PubMed_extended"],"metadata":{"id":"040v3lVjSPW0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648535706247,"user_tz":-60,"elapsed":211,"user":{"displayName":"Lya Solis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0zQkkPA02m_TCbUFh15I5DgeImYkaFOwSePgp=s64","userId":"00474828135331575492"}},"outputId":"57ebf09a-e3a9-48be-ed7e-294b4061a864"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":[" added_tokens.json\t   pubmed_config_ex_base_s3.json   tokenizer.json\n"," config.json\t\t   pytorch_model.bin\t\t   vocab.txt\n","'Copy of tokenizer.json'   special_tokens_map.json\n"," extended_vocab.txt\t   tokenizer_config.json\n"]}]},{"cell_type":"markdown","source":["Generate pre-training data. Please see https://github.com/google-research/bert for more details."],"metadata":{"id":"YlRuPnB5FIsH"}},{"cell_type":"code","source":["# Import generic wrappers\n","from transformers import AutoModel, AutoTokenizer, AutoConfig, AutoModelForMaskedLM"],"metadata":{"id":"hCFSGr2qO5lM","executionInfo":{"status":"ok","timestamp":1648535927602,"user_tz":-60,"elapsed":6230,"user":{"displayName":"Lya Solis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0zQkkPA02m_TCbUFh15I5DgeImYkaFOwSePgp=s64","userId":"00474828135331575492"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["updated_model = '/content/drive/MyDrive/GitHub/exBERT/PubMED_train_files/PubMed_extended'\n","config = AutoConfig.from_pretrained(updated_model)"],"metadata":{"id":"4Qcvgmz7Pq6m","executionInfo":{"status":"ok","timestamp":1648535932187,"user_tz":-60,"elapsed":233,"user":{"displayName":"Lya Solis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0zQkkPA02m_TCbUFh15I5DgeImYkaFOwSePgp=s64","userId":"00474828135331575492"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["model = AutoModelForMaskedLM.from_pretrained(updated_model, config=config)\n","tokenizer = AutoTokenizer.from_pretrained(updated_model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YWyH4W19Zf56","executionInfo":{"status":"ok","timestamp":1648535947506,"user_tz":-60,"elapsed":8721,"user":{"displayName":"Lya Solis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0zQkkPA02m_TCbUFh15I5DgeImYkaFOwSePgp=s64","userId":"00474828135331575492"}},"outputId":"6871a70c-8e69-4688-e775-5e94c8401a60"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForMaskedLM were not initialized from the model checkpoint at /content/drive/MyDrive/GitHub/exBERT/PubMED_train_files/PubMed_extended and are newly initialized: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["#Testing\n","from exBERT import BertTokenizer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uw537eC6ODNA","executionInfo":{"status":"ok","timestamp":1648535963438,"user_tz":-60,"elapsed":240,"user":{"displayName":"Lya Solis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0zQkkPA02m_TCbUFh15I5DgeImYkaFOwSePgp=s64","userId":"00474828135331575492"}},"outputId":"19e4fc93-1b16-4f36-a622-bcce23588a38"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"]}]},{"cell_type":"markdown","source":["Generating Training Data"],"metadata":{"id":"RVQQ8G14Stt7"}},{"cell_type":"code","source":["#For this we need raw text\n","!python /content/drive/MyDrive/GitHub/exBERT/data_preprocess.py -voc /content/drive/MyDrive/GitHub/exBERT/PubMED_train_files/PubMed_extended/extended_vocab.txt -ls 128 -dp /content/drive/MyDrive/GitHub/exBERT/data/exbert_train_data.txt -n_c 5 -rd 1 -sp /content/drive/MyDrive/GitHub/exBERT/data/exbert_train_data_output.pkl"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BTQ9OD4BODKJ","executionInfo":{"status":"ok","timestamp":1648536387929,"user_tz":-60,"elapsed":35553,"user":{"displayName":"Lya Solis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0zQkkPA02m_TCbUFh15I5DgeImYkaFOwSePgp=s64","userId":"00474828135331575492"}},"outputId":"bd0dbd20-825d-44c7-a300-41a19a0f837c"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n","processing data, thie might take some time\n","100% 5/5 [00:00<00:00, 52958.38it/s]\n","generating random sequence\n"]}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IhCevbGGODHz","executionInfo":{"status":"ok","timestamp":1648536410871,"user_tz":-60,"elapsed":226,"user":{"displayName":"Lya Solis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0zQkkPA02m_TCbUFh15I5DgeImYkaFOwSePgp=s64","userId":"00474828135331575492"}},"outputId":"ba1c6c37-a793-4cf4-e3d1-fb277e10536d"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Mar 29 06:46:54 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   42C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["device = 'cuda'\n","import torch, gc\n","import os\n","gc.collect()\n","torch.cuda.empty_cache()"],"metadata":{"id":"fq5uveypODFN","executionInfo":{"status":"ok","timestamp":1648536416472,"user_tz":-60,"elapsed":398,"user":{"displayName":"Lya Solis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0zQkkPA02m_TCbUFh15I5DgeImYkaFOwSePgp=s64","userId":"00474828135331575492"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["!python /content/drive/MyDrive/GitHub/exBERT/Pretraining.py -e 1 -b 4 -sp /content/drive/MyDrive/GitHub/exBERT/PubMED_train_files/PubMed_output -dv 0 -lr 1e-04 -str exBERT -config /content/drive/MyDrive/GitHub/exBERT/PubMED_train_files/PubMed_extended/config.json /content/drive/MyDrive/GitHub/exBERT/PubMED_train_files/PubMed_extended/pubmed_config_ex_base_s3.json -vocab /content/drive/MyDrive/GitHub/exBERT/PubMED_train_files/PubMed_extended/extended_vocab.txt -pm_p /content/drive/MyDrive/GitHub/exBERT/PubMED_train_files/PubMed_extended/pytorch_model.bin -dp /content/drive/MyDrive/GitHub/exBERT/data/exbert_train_data_output.pkl -ls 128 -p 1 -t_ex_only \"\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sshgHF2-ODCn","executionInfo":{"status":"ok","timestamp":1648537336447,"user_tz":-60,"elapsed":595544,"user":{"displayName":"Lya Solis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0zQkkPA02m_TCbUFh15I5DgeImYkaFOwSePgp=s64","userId":"00474828135331575492"}},"outputId":"2248e904-42ef-46d0-9050-90d6949879ed"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n","epochs: 1\n","batchsize: 4\n","save_path: /content/drive/MyDrive/GitHub/exBERT/PubMED_train_files/PubMed_output\n","device: [0]\n","learning_rate: 0.0001\n","strategy: exBERT\n","config: ['/content/drive/MyDrive/GitHub/exBERT/PubMED_train_files/PubMed_extended/config.json', '/content/drive/MyDrive/GitHub/exBERT/PubMED_train_files/PubMed_extended/pubmed_config_ex_base_s3.json']\n","vocab: /content/drive/MyDrive/GitHub/exBERT/PubMED_train_files/PubMed_extended/extended_vocab.txt\n","pretrained_model_path: /content/drive/MyDrive/GitHub/exBERT/PubMED_train_files/PubMed_extended/pytorch_model.bin\n","pretrained_model_path_tf: None\n","datat_path: /content/drive/MyDrive/GitHub/exBERT/data/exbert_train_data_output.pkl\n","longest_sentence: 128\n","percentage: 1.0\n","sep: 1\n","warmup: -1\n","train_extension_only: False\n","training with GPU: [0]\n","Building PyTorch model from configuration: {\n","  \"_name_or_path\": \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.17.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 35177\n","}\n","\n","Building PyTorch model from configuration: {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 4655\n","}\n","\n","The following part of model is goinig to be trained:\n","bert.embeddings.word_embeddings.weight\n","bert.embeddings.position_embeddings.weight\n","bert.embeddings.token_type_embeddings.weight\n","bert.embeddings.word_embeddings_ADD.weight\n","bert.embeddings.LayerNorm.weight\n","bert.embeddings.LayerNorm.bias\n","bert.encoder.layer.0.attention.self.query.weight\n","bert.encoder.layer.0.attention.self.query.bias\n","bert.encoder.layer.0.attention.self.key.weight\n","bert.encoder.layer.0.attention.self.key.bias\n","bert.encoder.layer.0.attention.self.value.weight\n","bert.encoder.layer.0.attention.self.value.bias\n","bert.encoder.layer.0.attention.output.dense.weight\n","bert.encoder.layer.0.attention.output.dense.bias\n","bert.encoder.layer.0.attention.output.LayerNorm.weight\n","bert.encoder.layer.0.attention.output.LayerNorm.bias\n","bert.encoder.layer.0.intermediate.dense.weight\n","bert.encoder.layer.0.intermediate.dense.bias\n","bert.encoder.layer.0.output.dense.weight\n","bert.encoder.layer.0.output.dense.bias\n","bert.encoder.layer.0.output.LayerNorm.weight\n","bert.encoder.layer.0.output.LayerNorm.bias\n","bert.encoder.layer.0.attention_ADD.self.query.weight\n","bert.encoder.layer.0.attention_ADD.self.query.bias\n","bert.encoder.layer.0.attention_ADD.self.key.weight\n","bert.encoder.layer.0.attention_ADD.self.key.bias\n","bert.encoder.layer.0.attention_ADD.self.value.weight\n","bert.encoder.layer.0.attention_ADD.self.value.bias\n","bert.encoder.layer.0.attention_ADD.output.dense.weight\n","bert.encoder.layer.0.attention_ADD.output.dense.bias\n","bert.encoder.layer.0.attention_ADD.output.LayerNorm.weight\n","bert.encoder.layer.0.attention_ADD.output.LayerNorm.bias\n","bert.encoder.layer.0.intermediate_ADD.dense.weight\n","bert.encoder.layer.0.intermediate_ADD.dense.bias\n","bert.encoder.layer.0.output_ADD.dense.weight\n","bert.encoder.layer.0.output_ADD.dense.bias\n","bert.encoder.layer.0.output_ADD.LayerNorm.weight\n","bert.encoder.layer.0.output_ADD.LayerNorm.bias\n","bert.encoder.layer.0.gate_ADD.weight\n","bert.encoder.layer.0.gate_ADD.bias\n","bert.encoder.layer.1.attention.self.query.weight\n","bert.encoder.layer.1.attention.self.query.bias\n","bert.encoder.layer.1.attention.self.key.weight\n","bert.encoder.layer.1.attention.self.key.bias\n","bert.encoder.layer.1.attention.self.value.weight\n","bert.encoder.layer.1.attention.self.value.bias\n","bert.encoder.layer.1.attention.output.dense.weight\n","bert.encoder.layer.1.attention.output.dense.bias\n","bert.encoder.layer.1.attention.output.LayerNorm.weight\n","bert.encoder.layer.1.attention.output.LayerNorm.bias\n","bert.encoder.layer.1.intermediate.dense.weight\n","bert.encoder.layer.1.intermediate.dense.bias\n","bert.encoder.layer.1.output.dense.weight\n","bert.encoder.layer.1.output.dense.bias\n","bert.encoder.layer.1.output.LayerNorm.weight\n","bert.encoder.layer.1.output.LayerNorm.bias\n","bert.encoder.layer.1.attention_ADD.self.query.weight\n","bert.encoder.layer.1.attention_ADD.self.query.bias\n","bert.encoder.layer.1.attention_ADD.self.key.weight\n","bert.encoder.layer.1.attention_ADD.self.key.bias\n","bert.encoder.layer.1.attention_ADD.self.value.weight\n","bert.encoder.layer.1.attention_ADD.self.value.bias\n","bert.encoder.layer.1.attention_ADD.output.dense.weight\n","bert.encoder.layer.1.attention_ADD.output.dense.bias\n","bert.encoder.layer.1.attention_ADD.output.LayerNorm.weight\n","bert.encoder.layer.1.attention_ADD.output.LayerNorm.bias\n","bert.encoder.layer.1.intermediate_ADD.dense.weight\n","bert.encoder.layer.1.intermediate_ADD.dense.bias\n","bert.encoder.layer.1.output_ADD.dense.weight\n","bert.encoder.layer.1.output_ADD.dense.bias\n","bert.encoder.layer.1.output_ADD.LayerNorm.weight\n","bert.encoder.layer.1.output_ADD.LayerNorm.bias\n","bert.encoder.layer.1.gate_ADD.weight\n","bert.encoder.layer.1.gate_ADD.bias\n","bert.encoder.layer.2.attention.self.query.weight\n","bert.encoder.layer.2.attention.self.query.bias\n","bert.encoder.layer.2.attention.self.key.weight\n","bert.encoder.layer.2.attention.self.key.bias\n","bert.encoder.layer.2.attention.self.value.weight\n","bert.encoder.layer.2.attention.self.value.bias\n","bert.encoder.layer.2.attention.output.dense.weight\n","bert.encoder.layer.2.attention.output.dense.bias\n","bert.encoder.layer.2.attention.output.LayerNorm.weight\n","bert.encoder.layer.2.attention.output.LayerNorm.bias\n","bert.encoder.layer.2.intermediate.dense.weight\n","bert.encoder.layer.2.intermediate.dense.bias\n","bert.encoder.layer.2.output.dense.weight\n","bert.encoder.layer.2.output.dense.bias\n","bert.encoder.layer.2.output.LayerNorm.weight\n","bert.encoder.layer.2.output.LayerNorm.bias\n","bert.encoder.layer.2.attention_ADD.self.query.weight\n","bert.encoder.layer.2.attention_ADD.self.query.bias\n","bert.encoder.layer.2.attention_ADD.self.key.weight\n","bert.encoder.layer.2.attention_ADD.self.key.bias\n","bert.encoder.layer.2.attention_ADD.self.value.weight\n","bert.encoder.layer.2.attention_ADD.self.value.bias\n","bert.encoder.layer.2.attention_ADD.output.dense.weight\n","bert.encoder.layer.2.attention_ADD.output.dense.bias\n","bert.encoder.layer.2.attention_ADD.output.LayerNorm.weight\n","bert.encoder.layer.2.attention_ADD.output.LayerNorm.bias\n","bert.encoder.layer.2.intermediate_ADD.dense.weight\n","bert.encoder.layer.2.intermediate_ADD.dense.bias\n","bert.encoder.layer.2.output_ADD.dense.weight\n","bert.encoder.layer.2.output_ADD.dense.bias\n","bert.encoder.layer.2.output_ADD.LayerNorm.weight\n","bert.encoder.layer.2.output_ADD.LayerNorm.bias\n","bert.encoder.layer.2.gate_ADD.weight\n","bert.encoder.layer.2.gate_ADD.bias\n","bert.encoder.layer.3.attention.self.query.weight\n","bert.encoder.layer.3.attention.self.query.bias\n","bert.encoder.layer.3.attention.self.key.weight\n","bert.encoder.layer.3.attention.self.key.bias\n","bert.encoder.layer.3.attention.self.value.weight\n","bert.encoder.layer.3.attention.self.value.bias\n","bert.encoder.layer.3.attention.output.dense.weight\n","bert.encoder.layer.3.attention.output.dense.bias\n","bert.encoder.layer.3.attention.output.LayerNorm.weight\n","bert.encoder.layer.3.attention.output.LayerNorm.bias\n","bert.encoder.layer.3.intermediate.dense.weight\n","bert.encoder.layer.3.intermediate.dense.bias\n","bert.encoder.layer.3.output.dense.weight\n","bert.encoder.layer.3.output.dense.bias\n","bert.encoder.layer.3.output.LayerNorm.weight\n","bert.encoder.layer.3.output.LayerNorm.bias\n","bert.encoder.layer.3.attention_ADD.self.query.weight\n","bert.encoder.layer.3.attention_ADD.self.query.bias\n","bert.encoder.layer.3.attention_ADD.self.key.weight\n","bert.encoder.layer.3.attention_ADD.self.key.bias\n","bert.encoder.layer.3.attention_ADD.self.value.weight\n","bert.encoder.layer.3.attention_ADD.self.value.bias\n","bert.encoder.layer.3.attention_ADD.output.dense.weight\n","bert.encoder.layer.3.attention_ADD.output.dense.bias\n","bert.encoder.layer.3.attention_ADD.output.LayerNorm.weight\n","bert.encoder.layer.3.attention_ADD.output.LayerNorm.bias\n","bert.encoder.layer.3.intermediate_ADD.dense.weight\n","bert.encoder.layer.3.intermediate_ADD.dense.bias\n","bert.encoder.layer.3.output_ADD.dense.weight\n","bert.encoder.layer.3.output_ADD.dense.bias\n","bert.encoder.layer.3.output_ADD.LayerNorm.weight\n","bert.encoder.layer.3.output_ADD.LayerNorm.bias\n","bert.encoder.layer.3.gate_ADD.weight\n","bert.encoder.layer.3.gate_ADD.bias\n","bert.encoder.layer.4.attention.self.query.weight\n","bert.encoder.layer.4.attention.self.query.bias\n","bert.encoder.layer.4.attention.self.key.weight\n","bert.encoder.layer.4.attention.self.key.bias\n","bert.encoder.layer.4.attention.self.value.weight\n","bert.encoder.layer.4.attention.self.value.bias\n","bert.encoder.layer.4.attention.output.dense.weight\n","bert.encoder.layer.4.attention.output.dense.bias\n","bert.encoder.layer.4.attention.output.LayerNorm.weight\n","bert.encoder.layer.4.attention.output.LayerNorm.bias\n","bert.encoder.layer.4.intermediate.dense.weight\n","bert.encoder.layer.4.intermediate.dense.bias\n","bert.encoder.layer.4.output.dense.weight\n","bert.encoder.layer.4.output.dense.bias\n","bert.encoder.layer.4.output.LayerNorm.weight\n","bert.encoder.layer.4.output.LayerNorm.bias\n","bert.encoder.layer.4.attention_ADD.self.query.weight\n","bert.encoder.layer.4.attention_ADD.self.query.bias\n","bert.encoder.layer.4.attention_ADD.self.key.weight\n","bert.encoder.layer.4.attention_ADD.self.key.bias\n","bert.encoder.layer.4.attention_ADD.self.value.weight\n","bert.encoder.layer.4.attention_ADD.self.value.bias\n","bert.encoder.layer.4.attention_ADD.output.dense.weight\n","bert.encoder.layer.4.attention_ADD.output.dense.bias\n","bert.encoder.layer.4.attention_ADD.output.LayerNorm.weight\n","bert.encoder.layer.4.attention_ADD.output.LayerNorm.bias\n","bert.encoder.layer.4.intermediate_ADD.dense.weight\n","bert.encoder.layer.4.intermediate_ADD.dense.bias\n","bert.encoder.layer.4.output_ADD.dense.weight\n","bert.encoder.layer.4.output_ADD.dense.bias\n","bert.encoder.layer.4.output_ADD.LayerNorm.weight\n","bert.encoder.layer.4.output_ADD.LayerNorm.bias\n","bert.encoder.layer.4.gate_ADD.weight\n","bert.encoder.layer.4.gate_ADD.bias\n","bert.encoder.layer.5.attention.self.query.weight\n","bert.encoder.layer.5.attention.self.query.bias\n","bert.encoder.layer.5.attention.self.key.weight\n","bert.encoder.layer.5.attention.self.key.bias\n","bert.encoder.layer.5.attention.self.value.weight\n","bert.encoder.layer.5.attention.self.value.bias\n","bert.encoder.layer.5.attention.output.dense.weight\n","bert.encoder.layer.5.attention.output.dense.bias\n","bert.encoder.layer.5.attention.output.LayerNorm.weight\n","bert.encoder.layer.5.attention.output.LayerNorm.bias\n","bert.encoder.layer.5.intermediate.dense.weight\n","bert.encoder.layer.5.intermediate.dense.bias\n","bert.encoder.layer.5.output.dense.weight\n","bert.encoder.layer.5.output.dense.bias\n","bert.encoder.layer.5.output.LayerNorm.weight\n","bert.encoder.layer.5.output.LayerNorm.bias\n","bert.encoder.layer.5.attention_ADD.self.query.weight\n","bert.encoder.layer.5.attention_ADD.self.query.bias\n","bert.encoder.layer.5.attention_ADD.self.key.weight\n","bert.encoder.layer.5.attention_ADD.self.key.bias\n","bert.encoder.layer.5.attention_ADD.self.value.weight\n","bert.encoder.layer.5.attention_ADD.self.value.bias\n","bert.encoder.layer.5.attention_ADD.output.dense.weight\n","bert.encoder.layer.5.attention_ADD.output.dense.bias\n","bert.encoder.layer.5.attention_ADD.output.LayerNorm.weight\n","bert.encoder.layer.5.attention_ADD.output.LayerNorm.bias\n","bert.encoder.layer.5.intermediate_ADD.dense.weight\n","bert.encoder.layer.5.intermediate_ADD.dense.bias\n","bert.encoder.layer.5.output_ADD.dense.weight\n","bert.encoder.layer.5.output_ADD.dense.bias\n","bert.encoder.layer.5.output_ADD.LayerNorm.weight\n","bert.encoder.layer.5.output_ADD.LayerNorm.bias\n","bert.encoder.layer.5.gate_ADD.weight\n","bert.encoder.layer.5.gate_ADD.bias\n","bert.encoder.layer.6.attention.self.query.weight\n","bert.encoder.layer.6.attention.self.query.bias\n","bert.encoder.layer.6.attention.self.key.weight\n","bert.encoder.layer.6.attention.self.key.bias\n","bert.encoder.layer.6.attention.self.value.weight\n","bert.encoder.layer.6.attention.self.value.bias\n","bert.encoder.layer.6.attention.output.dense.weight\n","bert.encoder.layer.6.attention.output.dense.bias\n","bert.encoder.layer.6.attention.output.LayerNorm.weight\n","bert.encoder.layer.6.attention.output.LayerNorm.bias\n","bert.encoder.layer.6.intermediate.dense.weight\n","bert.encoder.layer.6.intermediate.dense.bias\n","bert.encoder.layer.6.output.dense.weight\n","bert.encoder.layer.6.output.dense.bias\n","bert.encoder.layer.6.output.LayerNorm.weight\n","bert.encoder.layer.6.output.LayerNorm.bias\n","bert.encoder.layer.6.attention_ADD.self.query.weight\n","bert.encoder.layer.6.attention_ADD.self.query.bias\n","bert.encoder.layer.6.attention_ADD.self.key.weight\n","bert.encoder.layer.6.attention_ADD.self.key.bias\n","bert.encoder.layer.6.attention_ADD.self.value.weight\n","bert.encoder.layer.6.attention_ADD.self.value.bias\n","bert.encoder.layer.6.attention_ADD.output.dense.weight\n","bert.encoder.layer.6.attention_ADD.output.dense.bias\n","bert.encoder.layer.6.attention_ADD.output.LayerNorm.weight\n","bert.encoder.layer.6.attention_ADD.output.LayerNorm.bias\n","bert.encoder.layer.6.intermediate_ADD.dense.weight\n","bert.encoder.layer.6.intermediate_ADD.dense.bias\n","bert.encoder.layer.6.output_ADD.dense.weight\n","bert.encoder.layer.6.output_ADD.dense.bias\n","bert.encoder.layer.6.output_ADD.LayerNorm.weight\n","bert.encoder.layer.6.output_ADD.LayerNorm.bias\n","bert.encoder.layer.6.gate_ADD.weight\n","bert.encoder.layer.6.gate_ADD.bias\n","bert.encoder.layer.7.attention.self.query.weight\n","bert.encoder.layer.7.attention.self.query.bias\n","bert.encoder.layer.7.attention.self.key.weight\n","bert.encoder.layer.7.attention.self.key.bias\n","bert.encoder.layer.7.attention.self.value.weight\n","bert.encoder.layer.7.attention.self.value.bias\n","bert.encoder.layer.7.attention.output.dense.weight\n","bert.encoder.layer.7.attention.output.dense.bias\n","bert.encoder.layer.7.attention.output.LayerNorm.weight\n","bert.encoder.layer.7.attention.output.LayerNorm.bias\n","bert.encoder.layer.7.intermediate.dense.weight\n","bert.encoder.layer.7.intermediate.dense.bias\n","bert.encoder.layer.7.output.dense.weight\n","bert.encoder.layer.7.output.dense.bias\n","bert.encoder.layer.7.output.LayerNorm.weight\n","bert.encoder.layer.7.output.LayerNorm.bias\n","bert.encoder.layer.7.attention_ADD.self.query.weight\n","bert.encoder.layer.7.attention_ADD.self.query.bias\n","bert.encoder.layer.7.attention_ADD.self.key.weight\n","bert.encoder.layer.7.attention_ADD.self.key.bias\n","bert.encoder.layer.7.attention_ADD.self.value.weight\n","bert.encoder.layer.7.attention_ADD.self.value.bias\n","bert.encoder.layer.7.attention_ADD.output.dense.weight\n","bert.encoder.layer.7.attention_ADD.output.dense.bias\n","bert.encoder.layer.7.attention_ADD.output.LayerNorm.weight\n","bert.encoder.layer.7.attention_ADD.output.LayerNorm.bias\n","bert.encoder.layer.7.intermediate_ADD.dense.weight\n","bert.encoder.layer.7.intermediate_ADD.dense.bias\n","bert.encoder.layer.7.output_ADD.dense.weight\n","bert.encoder.layer.7.output_ADD.dense.bias\n","bert.encoder.layer.7.output_ADD.LayerNorm.weight\n","bert.encoder.layer.7.output_ADD.LayerNorm.bias\n","bert.encoder.layer.7.gate_ADD.weight\n","bert.encoder.layer.7.gate_ADD.bias\n","bert.encoder.layer.8.attention.self.query.weight\n","bert.encoder.layer.8.attention.self.query.bias\n","bert.encoder.layer.8.attention.self.key.weight\n","bert.encoder.layer.8.attention.self.key.bias\n","bert.encoder.layer.8.attention.self.value.weight\n","bert.encoder.layer.8.attention.self.value.bias\n","bert.encoder.layer.8.attention.output.dense.weight\n","bert.encoder.layer.8.attention.output.dense.bias\n","bert.encoder.layer.8.attention.output.LayerNorm.weight\n","bert.encoder.layer.8.attention.output.LayerNorm.bias\n","bert.encoder.layer.8.intermediate.dense.weight\n","bert.encoder.layer.8.intermediate.dense.bias\n","bert.encoder.layer.8.output.dense.weight\n","bert.encoder.layer.8.output.dense.bias\n","bert.encoder.layer.8.output.LayerNorm.weight\n","bert.encoder.layer.8.output.LayerNorm.bias\n","bert.encoder.layer.8.attention_ADD.self.query.weight\n","bert.encoder.layer.8.attention_ADD.self.query.bias\n","bert.encoder.layer.8.attention_ADD.self.key.weight\n","bert.encoder.layer.8.attention_ADD.self.key.bias\n","bert.encoder.layer.8.attention_ADD.self.value.weight\n","bert.encoder.layer.8.attention_ADD.self.value.bias\n","bert.encoder.layer.8.attention_ADD.output.dense.weight\n","bert.encoder.layer.8.attention_ADD.output.dense.bias\n","bert.encoder.layer.8.attention_ADD.output.LayerNorm.weight\n","bert.encoder.layer.8.attention_ADD.output.LayerNorm.bias\n","bert.encoder.layer.8.intermediate_ADD.dense.weight\n","bert.encoder.layer.8.intermediate_ADD.dense.bias\n","bert.encoder.layer.8.output_ADD.dense.weight\n","bert.encoder.layer.8.output_ADD.dense.bias\n","bert.encoder.layer.8.output_ADD.LayerNorm.weight\n","bert.encoder.layer.8.output_ADD.LayerNorm.bias\n","bert.encoder.layer.8.gate_ADD.weight\n","bert.encoder.layer.8.gate_ADD.bias\n","bert.encoder.layer.9.attention.self.query.weight\n","bert.encoder.layer.9.attention.self.query.bias\n","bert.encoder.layer.9.attention.self.key.weight\n","bert.encoder.layer.9.attention.self.key.bias\n","bert.encoder.layer.9.attention.self.value.weight\n","bert.encoder.layer.9.attention.self.value.bias\n","bert.encoder.layer.9.attention.output.dense.weight\n","bert.encoder.layer.9.attention.output.dense.bias\n","bert.encoder.layer.9.attention.output.LayerNorm.weight\n","bert.encoder.layer.9.attention.output.LayerNorm.bias\n","bert.encoder.layer.9.intermediate.dense.weight\n","bert.encoder.layer.9.intermediate.dense.bias\n","bert.encoder.layer.9.output.dense.weight\n","bert.encoder.layer.9.output.dense.bias\n","bert.encoder.layer.9.output.LayerNorm.weight\n","bert.encoder.layer.9.output.LayerNorm.bias\n","bert.encoder.layer.9.attention_ADD.self.query.weight\n","bert.encoder.layer.9.attention_ADD.self.query.bias\n","bert.encoder.layer.9.attention_ADD.self.key.weight\n","bert.encoder.layer.9.attention_ADD.self.key.bias\n","bert.encoder.layer.9.attention_ADD.self.value.weight\n","bert.encoder.layer.9.attention_ADD.self.value.bias\n","bert.encoder.layer.9.attention_ADD.output.dense.weight\n","bert.encoder.layer.9.attention_ADD.output.dense.bias\n","bert.encoder.layer.9.attention_ADD.output.LayerNorm.weight\n","bert.encoder.layer.9.attention_ADD.output.LayerNorm.bias\n","bert.encoder.layer.9.intermediate_ADD.dense.weight\n","bert.encoder.layer.9.intermediate_ADD.dense.bias\n","bert.encoder.layer.9.output_ADD.dense.weight\n","bert.encoder.layer.9.output_ADD.dense.bias\n","bert.encoder.layer.9.output_ADD.LayerNorm.weight\n","bert.encoder.layer.9.output_ADD.LayerNorm.bias\n","bert.encoder.layer.9.gate_ADD.weight\n","bert.encoder.layer.9.gate_ADD.bias\n","bert.encoder.layer.10.attention.self.query.weight\n","bert.encoder.layer.10.attention.self.query.bias\n","bert.encoder.layer.10.attention.self.key.weight\n","bert.encoder.layer.10.attention.self.key.bias\n","bert.encoder.layer.10.attention.self.value.weight\n","bert.encoder.layer.10.attention.self.value.bias\n","bert.encoder.layer.10.attention.output.dense.weight\n","bert.encoder.layer.10.attention.output.dense.bias\n","bert.encoder.layer.10.attention.output.LayerNorm.weight\n","bert.encoder.layer.10.attention.output.LayerNorm.bias\n","bert.encoder.layer.10.intermediate.dense.weight\n","bert.encoder.layer.10.intermediate.dense.bias\n","bert.encoder.layer.10.output.dense.weight\n","bert.encoder.layer.10.output.dense.bias\n","bert.encoder.layer.10.output.LayerNorm.weight\n","bert.encoder.layer.10.output.LayerNorm.bias\n","bert.encoder.layer.10.attention_ADD.self.query.weight\n","bert.encoder.layer.10.attention_ADD.self.query.bias\n","bert.encoder.layer.10.attention_ADD.self.key.weight\n","bert.encoder.layer.10.attention_ADD.self.key.bias\n","bert.encoder.layer.10.attention_ADD.self.value.weight\n","bert.encoder.layer.10.attention_ADD.self.value.bias\n","bert.encoder.layer.10.attention_ADD.output.dense.weight\n","bert.encoder.layer.10.attention_ADD.output.dense.bias\n","bert.encoder.layer.10.attention_ADD.output.LayerNorm.weight\n","bert.encoder.layer.10.attention_ADD.output.LayerNorm.bias\n","bert.encoder.layer.10.intermediate_ADD.dense.weight\n","bert.encoder.layer.10.intermediate_ADD.dense.bias\n","bert.encoder.layer.10.output_ADD.dense.weight\n","bert.encoder.layer.10.output_ADD.dense.bias\n","bert.encoder.layer.10.output_ADD.LayerNorm.weight\n","bert.encoder.layer.10.output_ADD.LayerNorm.bias\n","bert.encoder.layer.10.gate_ADD.weight\n","bert.encoder.layer.10.gate_ADD.bias\n","bert.encoder.layer.11.attention.self.query.weight\n","bert.encoder.layer.11.attention.self.query.bias\n","bert.encoder.layer.11.attention.self.key.weight\n","bert.encoder.layer.11.attention.self.key.bias\n","bert.encoder.layer.11.attention.self.value.weight\n","bert.encoder.layer.11.attention.self.value.bias\n","bert.encoder.layer.11.attention.output.dense.weight\n","bert.encoder.layer.11.attention.output.dense.bias\n","bert.encoder.layer.11.attention.output.LayerNorm.weight\n","bert.encoder.layer.11.attention.output.LayerNorm.bias\n","bert.encoder.layer.11.intermediate.dense.weight\n","bert.encoder.layer.11.intermediate.dense.bias\n","bert.encoder.layer.11.output.dense.weight\n","bert.encoder.layer.11.output.dense.bias\n","bert.encoder.layer.11.output.LayerNorm.weight\n","bert.encoder.layer.11.output.LayerNorm.bias\n","bert.encoder.layer.11.attention_ADD.self.query.weight\n","bert.encoder.layer.11.attention_ADD.self.query.bias\n","bert.encoder.layer.11.attention_ADD.self.key.weight\n","bert.encoder.layer.11.attention_ADD.self.key.bias\n","bert.encoder.layer.11.attention_ADD.self.value.weight\n","bert.encoder.layer.11.attention_ADD.self.value.bias\n","bert.encoder.layer.11.attention_ADD.output.dense.weight\n","bert.encoder.layer.11.attention_ADD.output.dense.bias\n","bert.encoder.layer.11.attention_ADD.output.LayerNorm.weight\n","bert.encoder.layer.11.attention_ADD.output.LayerNorm.bias\n","bert.encoder.layer.11.intermediate_ADD.dense.weight\n","bert.encoder.layer.11.intermediate_ADD.dense.bias\n","bert.encoder.layer.11.output_ADD.dense.weight\n","bert.encoder.layer.11.output_ADD.dense.bias\n","bert.encoder.layer.11.output_ADD.LayerNorm.weight\n","bert.encoder.layer.11.output_ADD.LayerNorm.bias\n","bert.encoder.layer.11.gate_ADD.weight\n","bert.encoder.layer.11.gate_ADD.bias\n","bert.pooler.dense.weight\n","bert.pooler.dense.bias\n","cls.predictions.bias\n","cls.predictions.bias_ADD\n","cls.predictions.transform.dense.weight\n","cls.predictions.transform.dense.bias\n","cls.predictions.transform.LayerNorm.weight\n","cls.predictions.transform.LayerNorm.bias\n","cls.seq_relationship.weight\n","cls.seq_relationship.bias\n","loading data: /content/drive/MyDrive/GitHub/exBERT/data/exbert_train_data_output.pkl\n","shuffle data\n","done data preparation\n","data number: 6456\n","loading data: /content/drive/MyDrive/GitHub/exBERT/data/exbert_train_data_output.pkl\n","shuffle data\n","/content/drive/MyDrive/GitHub/exBERT/exBERT/optimization.py:133: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)\n","  next_m.mul_(beta1).add_(1 - beta1, grad)\n","Train Epoch: 0 [32/6456 (0%)]\ttrain_Loss: 3.03009 \tval_Loss: 0.00000 time: 3.1684 \t lr:0.000099\n","Train Epoch: 0 [64/6456 (1%)]\ttrain_Loss: 2.35430 \tval_Loss: 0.00000 time: 6.0814 \t lr:0.000099\n","Train Epoch: 0 [96/6456 (1%)]\ttrain_Loss: 2.08007 \tval_Loss: 0.00000 time: 8.7800 \t lr:0.000098\n","Train Epoch: 0 [128/6456 (2%)]\ttrain_Loss: 2.00675 \tval_Loss: 0.00000 time: 11.4901 \t lr:0.000098\n","Train Epoch: 0 [160/6456 (2%)]\ttrain_Loss: 2.03569 \tval_Loss: 0.00000 time: 14.1735 \t lr:0.000097\n","Train Epoch: 0 [192/6456 (3%)]\ttrain_Loss: 2.01990 \tval_Loss: 0.00000 time: 16.8663 \t lr:0.000097\n","Train Epoch: 0 [224/6456 (3%)]\ttrain_Loss: 1.98049 \tval_Loss: 0.00000 time: 19.5644 \t lr:0.000096\n","Train Epoch: 0 [256/6456 (4%)]\ttrain_Loss: 1.96272 \tval_Loss: 0.00000 time: 22.2575 \t lr:0.000096\n","Train Epoch: 0 [288/6456 (4%)]\ttrain_Loss: 1.93632 \tval_Loss: 0.00000 time: 24.9631 \t lr:0.000095\n","Train Epoch: 0 [320/6456 (5%)]\ttrain_Loss: 1.96029 \tval_Loss: 0.00000 time: 27.6534 \t lr:0.000095\n","Train Epoch: 0 [352/6456 (5%)]\ttrain_Loss: 1.97191 \tval_Loss: 0.00000 time: 30.3521 \t lr:0.000094\n","Train Epoch: 0 [384/6456 (6%)]\ttrain_Loss: 1.84325 \tval_Loss: 0.00000 time: 33.0705 \t lr:0.000094\n","Train Epoch: 0 [416/6456 (6%)]\ttrain_Loss: 1.87423 \tval_Loss: 0.00000 time: 35.7868 \t lr:0.000093\n","Train Epoch: 0 [448/6456 (7%)]\ttrain_Loss: 1.87701 \tval_Loss: 0.00000 time: 38.4996 \t lr:0.000093\n","Train Epoch: 0 [480/6456 (7%)]\ttrain_Loss: 1.90209 \tval_Loss: 0.00000 time: 41.1941 \t lr:0.000093\n","Train Epoch: 0 [512/6456 (8%)]\ttrain_Loss: 1.88212 \tval_Loss: 0.00000 time: 43.9235 \t lr:0.000092\n","Train Epoch: 0 [544/6456 (8%)]\ttrain_Loss: 1.88824 \tval_Loss: 0.00000 time: 46.6630 \t lr:0.000092\n","Train Epoch: 0 [576/6456 (9%)]\ttrain_Loss: 1.93085 \tval_Loss: 0.00000 time: 49.3835 \t lr:0.000091\n","Train Epoch: 0 [608/6456 (9%)]\ttrain_Loss: 1.91286 \tval_Loss: 0.00000 time: 52.0980 \t lr:0.000091\n","Train Epoch: 0 [640/6456 (10%)]\ttrain_Loss: 1.87290 \tval_Loss: 0.00000 time: 54.8041 \t lr:0.000090\n","Train Epoch: 0 [672/6456 (10%)]\ttrain_Loss: 1.96221 \tval_Loss: 0.00000 time: 57.5073 \t lr:0.000090\n","Train Epoch: 0 [704/6456 (11%)]\ttrain_Loss: 1.87985 \tval_Loss: 0.00000 time: 60.1970 \t lr:0.000089\n","Train Epoch: 0 [736/6456 (11%)]\ttrain_Loss: 1.94010 \tval_Loss: 0.00000 time: 62.8928 \t lr:0.000089\n","Train Epoch: 0 [768/6456 (12%)]\ttrain_Loss: 1.86535 \tval_Loss: 0.00000 time: 65.5840 \t lr:0.000088\n","Train Epoch: 0 [800/6456 (12%)]\ttrain_Loss: 1.86963 \tval_Loss: 0.00000 time: 68.2982 \t lr:0.000088\n","Train Epoch: 0 [832/6456 (13%)]\ttrain_Loss: 1.90810 \tval_Loss: 0.00000 time: 71.0125 \t lr:0.000087\n","Train Epoch: 0 [864/6456 (13%)]\ttrain_Loss: 1.90772 \tval_Loss: 0.00000 time: 73.7159 \t lr:0.000087\n","Train Epoch: 0 [896/6456 (14%)]\ttrain_Loss: 1.88116 \tval_Loss: 0.00000 time: 76.4273 \t lr:0.000086\n","Train Epoch: 0 [928/6456 (14%)]\ttrain_Loss: 1.89679 \tval_Loss: 0.00000 time: 79.1388 \t lr:0.000086\n","Train Epoch: 0 [960/6456 (15%)]\ttrain_Loss: 1.92917 \tval_Loss: 0.00000 time: 81.8504 \t lr:0.000085\n","Train Epoch: 0 [992/6456 (15%)]\ttrain_Loss: 1.88805 \tval_Loss: 0.00000 time: 84.5397 \t lr:0.000085\n","Train Epoch: 0 [1024/6456 (16%)]\ttrain_Loss: 1.82372 \tval_Loss: 0.00000 time: 87.2697 \t lr:0.000084\n","Train Epoch: 0 [1056/6456 (16%)]\ttrain_Loss: 1.91625 \tval_Loss: 0.00000 time: 90.0023 \t lr:0.000084\n","Train Epoch: 0 [1088/6456 (17%)]\ttrain_Loss: 1.79749 \tval_Loss: 0.00000 time: 92.7113 \t lr:0.000083\n","Train Epoch: 0 [1120/6456 (17%)]\ttrain_Loss: 1.78755 \tval_Loss: 0.00000 time: 95.4225 \t lr:0.000083\n","Train Epoch: 0 [1152/6456 (18%)]\ttrain_Loss: 1.82963 \tval_Loss: 0.00000 time: 98.1585 \t lr:0.000082\n","Train Epoch: 0 [1184/6456 (18%)]\ttrain_Loss: 1.83373 \tval_Loss: 0.00000 time: 100.8781 \t lr:0.000082\n","Train Epoch: 0 [1216/6456 (19%)]\ttrain_Loss: 1.78999 \tval_Loss: 0.00000 time: 103.5833 \t lr:0.000081\n","Train Epoch: 0 [1248/6456 (19%)]\ttrain_Loss: 1.84170 \tval_Loss: 0.00000 time: 106.2808 \t lr:0.000081\n","Train Epoch: 0 [1280/6456 (20%)]\ttrain_Loss: 1.87475 \tval_Loss: 0.00000 time: 108.9803 \t lr:0.000080\n","Train Epoch: 0 [1312/6456 (20%)]\ttrain_Loss: 1.84879 \tval_Loss: 0.00000 time: 111.6871 \t lr:0.000080\n","Train Epoch: 0 [1344/6456 (21%)]\ttrain_Loss: 1.79786 \tval_Loss: 0.00000 time: 114.4061 \t lr:0.000079\n","Train Epoch: 0 [1376/6456 (21%)]\ttrain_Loss: 1.87620 \tval_Loss: 0.00000 time: 117.0969 \t lr:0.000079\n","Train Epoch: 0 [1408/6456 (22%)]\ttrain_Loss: 1.83549 \tval_Loss: 0.00000 time: 119.8296 \t lr:0.000078\n","Train Epoch: 0 [1440/6456 (22%)]\ttrain_Loss: 1.85064 \tval_Loss: 0.00000 time: 122.5263 \t lr:0.000078\n","Train Epoch: 0 [1472/6456 (23%)]\ttrain_Loss: 1.86324 \tval_Loss: 0.00000 time: 125.2301 \t lr:0.000077\n","Train Epoch: 0 [1504/6456 (23%)]\ttrain_Loss: 1.89612 \tval_Loss: 0.00000 time: 127.9502 \t lr:0.000077\n","Train Epoch: 0 [1536/6456 (24%)]\ttrain_Loss: 1.79329 \tval_Loss: 0.00000 time: 130.6447 \t lr:0.000076\n","Train Epoch: 0 [1568/6456 (24%)]\ttrain_Loss: 1.83586 \tval_Loss: 0.00000 time: 133.3496 \t lr:0.000076\n","Train Epoch: 0 [1600/6456 (25%)]\ttrain_Loss: 1.87959 \tval_Loss: 0.00000 time: 136.0865 \t lr:0.000075\n","Train Epoch: 0 [1632/6456 (25%)]\ttrain_Loss: 1.83389 \tval_Loss: 0.00000 time: 138.7808 \t lr:0.000075\n","Train Epoch: 0 [1664/6456 (26%)]\ttrain_Loss: 1.82712 \tval_Loss: 0.00000 time: 141.5010 \t lr:0.000074\n","Train Epoch: 0 [1696/6456 (26%)]\ttrain_Loss: 1.86250 \tval_Loss: 0.00000 time: 144.1924 \t lr:0.000074\n","Train Epoch: 0 [1728/6456 (27%)]\ttrain_Loss: 1.79245 \tval_Loss: 0.00000 time: 146.8963 \t lr:0.000073\n","Train Epoch: 0 [1760/6456 (27%)]\ttrain_Loss: 1.84078 \tval_Loss: 0.00000 time: 149.6284 \t lr:0.000073\n","Train Epoch: 0 [1792/6456 (28%)]\ttrain_Loss: 1.76189 \tval_Loss: 0.00000 time: 152.3110 \t lr:0.000072\n","Train Epoch: 0 [1824/6456 (28%)]\ttrain_Loss: 1.87675 \tval_Loss: 0.00000 time: 155.0031 \t lr:0.000072\n","Train Epoch: 0 [1856/6456 (29%)]\ttrain_Loss: 1.80404 \tval_Loss: 0.00000 time: 157.7290 \t lr:0.000071\n","Train Epoch: 0 [1888/6456 (29%)]\ttrain_Loss: 1.80406 \tval_Loss: 0.00000 time: 160.4485 \t lr:0.000071\n","Train Epoch: 0 [1920/6456 (30%)]\ttrain_Loss: 1.85049 \tval_Loss: 0.00000 time: 163.1535 \t lr:0.000070\n","Train Epoch: 0 [1952/6456 (30%)]\ttrain_Loss: 1.83217 \tval_Loss: 0.00000 time: 165.8524 \t lr:0.000070\n","Train Epoch: 0 [1984/6456 (31%)]\ttrain_Loss: 1.83771 \tval_Loss: 0.00000 time: 168.5457 \t lr:0.000069\n","Train Epoch: 0 [2016/6456 (31%)]\ttrain_Loss: 1.78280 \tval_Loss: 0.00000 time: 171.2287 \t lr:0.000069\n","Train Epoch: 0 [2048/6456 (32%)]\ttrain_Loss: 1.86929 \tval_Loss: 0.00000 time: 173.9341 \t lr:0.000068\n","Train Epoch: 0 [2080/6456 (32%)]\ttrain_Loss: 1.83752 \tval_Loss: 0.00000 time: 176.6441 \t lr:0.000068\n","Train Epoch: 0 [2112/6456 (33%)]\ttrain_Loss: 1.85515 \tval_Loss: 0.00000 time: 179.3617 \t lr:0.000067\n","Train Epoch: 0 [2144/6456 (33%)]\ttrain_Loss: 1.81833 \tval_Loss: 0.00000 time: 182.0679 \t lr:0.000067\n","Train Epoch: 0 [2176/6456 (34%)]\ttrain_Loss: 1.85194 \tval_Loss: 0.00000 time: 184.7826 \t lr:0.000066\n","Train Epoch: 0 [2208/6456 (34%)]\ttrain_Loss: 1.82682 \tval_Loss: 0.00000 time: 187.4991 \t lr:0.000066\n","Train Epoch: 0 [2240/6456 (35%)]\ttrain_Loss: 1.79148 \tval_Loss: 0.00000 time: 190.2043 \t lr:0.000065\n","Train Epoch: 0 [2272/6456 (35%)]\ttrain_Loss: 1.83926 \tval_Loss: 0.00000 time: 192.9073 \t lr:0.000065\n","Train Epoch: 0 [2304/6456 (36%)]\ttrain_Loss: 1.77499 \tval_Loss: 0.00000 time: 195.6281 \t lr:0.000064\n","Train Epoch: 0 [2336/6456 (36%)]\ttrain_Loss: 1.73463 \tval_Loss: 0.00000 time: 198.3349 \t lr:0.000064\n","Train Epoch: 0 [2368/6456 (37%)]\ttrain_Loss: 1.78179 \tval_Loss: 0.00000 time: 201.0332 \t lr:0.000063\n","Train Epoch: 0 [2400/6456 (37%)]\ttrain_Loss: 1.78206 \tval_Loss: 0.00000 time: 203.7425 \t lr:0.000063\n","Train Epoch: 0 [2432/6456 (38%)]\ttrain_Loss: 1.79192 \tval_Loss: 0.00000 time: 206.4407 \t lr:0.000062\n","Train Epoch: 0 [2464/6456 (38%)]\ttrain_Loss: 1.82200 \tval_Loss: 0.00000 time: 209.1537 \t lr:0.000062\n","Train Epoch: 0 [2496/6456 (39%)]\ttrain_Loss: 1.86424 \tval_Loss: 0.00000 time: 211.8663 \t lr:0.000061\n","Train Epoch: 0 [2528/6456 (39%)]\ttrain_Loss: 1.81018 \tval_Loss: 0.00000 time: 214.5619 \t lr:0.000061\n","Train Epoch: 0 [2560/6456 (40%)]\ttrain_Loss: 1.81248 \tval_Loss: 0.00000 time: 217.2732 \t lr:0.000060\n","Train Epoch: 0 [2592/6456 (40%)]\ttrain_Loss: 1.82438 \tval_Loss: 0.00000 time: 219.9918 \t lr:0.000060\n","Train Epoch: 0 [2624/6456 (41%)]\ttrain_Loss: 1.84711 \tval_Loss: 0.00000 time: 222.7188 \t lr:0.000059\n","Train Epoch: 0 [2656/6456 (41%)]\ttrain_Loss: 1.79887 \tval_Loss: 0.00000 time: 225.4265 \t lr:0.000059\n","Train Epoch: 0 [2688/6456 (42%)]\ttrain_Loss: 1.82837 \tval_Loss: 0.00000 time: 228.1457 \t lr:0.000058\n","Train Epoch: 0 [2720/6456 (42%)]\ttrain_Loss: 1.80645 \tval_Loss: 0.00000 time: 230.8576 \t lr:0.000058\n","Train Epoch: 0 [2752/6456 (43%)]\ttrain_Loss: 1.81975 \tval_Loss: 0.00000 time: 233.5267 \t lr:0.000057\n","Train Epoch: 0 [2784/6456 (43%)]\ttrain_Loss: 1.81523 \tval_Loss: 0.00000 time: 236.2244 \t lr:0.000057\n","Train Epoch: 0 [2816/6456 (44%)]\ttrain_Loss: 1.81346 \tval_Loss: 0.00000 time: 238.9277 \t lr:0.000056\n","Train Epoch: 0 [2848/6456 (44%)]\ttrain_Loss: 1.82835 \tval_Loss: 0.00000 time: 241.6162 \t lr:0.000056\n","Train Epoch: 0 [2880/6456 (45%)]\ttrain_Loss: 1.86029 \tval_Loss: 0.00000 time: 244.3302 \t lr:0.000055\n","Train Epoch: 0 [2912/6456 (45%)]\ttrain_Loss: 1.81214 \tval_Loss: 0.00000 time: 247.0375 \t lr:0.000055\n","Train Epoch: 0 [2944/6456 (46%)]\ttrain_Loss: 1.77942 \tval_Loss: 0.00000 time: 249.7459 \t lr:0.000054\n","Train Epoch: 0 [2976/6456 (46%)]\ttrain_Loss: 1.83302 \tval_Loss: 0.00000 time: 252.4511 \t lr:0.000054\n","Train Epoch: 0 [3008/6456 (47%)]\ttrain_Loss: 1.89381 \tval_Loss: 0.00000 time: 255.1846 \t lr:0.000053\n","Train Epoch: 0 [3040/6456 (47%)]\ttrain_Loss: 1.81494 \tval_Loss: 0.00000 time: 257.8966 \t lr:0.000053\n","Train Epoch: 0 [3072/6456 (48%)]\ttrain_Loss: 1.74747 \tval_Loss: 0.00000 time: 260.6141 \t lr:0.000052\n","Train Epoch: 0 [3104/6456 (48%)]\ttrain_Loss: 1.85105 \tval_Loss: 0.00000 time: 263.3703 \t lr:0.000052\n","Train Epoch: 0 [3136/6456 (49%)]\ttrain_Loss: 1.84657 \tval_Loss: 0.00000 time: 266.0719 \t lr:0.000051\n","Train Epoch: 0 [3168/6456 (49%)]\ttrain_Loss: 1.77130 \tval_Loss: 0.00000 time: 268.8117 \t lr:0.000051\n","Train Epoch: 0 [3200/6456 (50%)]\ttrain_Loss: 1.87429 \tval_Loss: 0.00000 time: 271.5012 \t lr:0.000050\n","Train Epoch: 0 [3232/6456 (50%)]\ttrain_Loss: 1.78633 \tval_Loss: 0.00000 time: 274.2029 \t lr:0.000050\n","Train Epoch: 0 [3264/6456 (51%)]\ttrain_Loss: 1.78399 \tval_Loss: 0.00000 time: 276.9056 \t lr:0.000049\n","Train Epoch: 0 [3296/6456 (51%)]\ttrain_Loss: 1.84939 \tval_Loss: 0.00000 time: 279.6149 \t lr:0.000049\n","Train Epoch: 0 [3328/6456 (52%)]\ttrain_Loss: 1.78924 \tval_Loss: 0.00000 time: 282.3380 \t lr:0.000048\n","Train Epoch: 0 [3360/6456 (52%)]\ttrain_Loss: 1.80791 \tval_Loss: 0.00000 time: 285.0660 \t lr:0.000048\n","Train Epoch: 0 [3392/6456 (53%)]\ttrain_Loss: 1.74861 \tval_Loss: 0.00000 time: 287.7627 \t lr:0.000047\n","Train Epoch: 0 [3424/6456 (53%)]\ttrain_Loss: 1.86133 \tval_Loss: 0.00000 time: 290.4575 \t lr:0.000047\n","Train Epoch: 0 [3456/6456 (54%)]\ttrain_Loss: 1.84549 \tval_Loss: 0.00000 time: 293.1633 \t lr:0.000046\n","Train Epoch: 0 [3488/6456 (54%)]\ttrain_Loss: 1.84398 \tval_Loss: 0.00000 time: 295.8540 \t lr:0.000046\n","Train Epoch: 0 [3520/6456 (55%)]\ttrain_Loss: 1.79871 \tval_Loss: 0.00000 time: 298.5632 \t lr:0.000045\n","Train Epoch: 0 [3552/6456 (55%)]\ttrain_Loss: 1.84732 \tval_Loss: 0.00000 time: 301.2703 \t lr:0.000045\n","Train Epoch: 0 [3584/6456 (56%)]\ttrain_Loss: 1.79795 \tval_Loss: 0.00000 time: 303.9480 \t lr:0.000044\n","Train Epoch: 0 [3616/6456 (56%)]\ttrain_Loss: 1.89160 \tval_Loss: 0.00000 time: 306.5853 \t lr:0.000044\n","Train Epoch: 0 [3648/6456 (57%)]\ttrain_Loss: 1.79235 \tval_Loss: 0.00000 time: 309.2571 \t lr:0.000043\n","Train Epoch: 0 [3680/6456 (57%)]\ttrain_Loss: 1.78304 \tval_Loss: 0.00000 time: 311.8892 \t lr:0.000043\n","Train Epoch: 0 [3712/6456 (57%)]\ttrain_Loss: 1.79167 \tval_Loss: 0.00000 time: 314.5337 \t lr:0.000042\n","Train Epoch: 0 [3744/6456 (58%)]\ttrain_Loss: 1.84240 \tval_Loss: 0.00000 time: 317.1913 \t lr:0.000042\n","Train Epoch: 0 [3776/6456 (58%)]\ttrain_Loss: 1.80817 \tval_Loss: 0.00000 time: 319.8263 \t lr:0.000041\n","Train Epoch: 0 [3808/6456 (59%)]\ttrain_Loss: 1.84276 \tval_Loss: 0.00000 time: 322.4657 \t lr:0.000041\n","Train Epoch: 0 [3840/6456 (59%)]\ttrain_Loss: 1.81687 \tval_Loss: 0.00000 time: 325.1397 \t lr:0.000040\n","Train Epoch: 0 [3872/6456 (60%)]\ttrain_Loss: 1.77747 \tval_Loss: 0.00000 time: 327.7833 \t lr:0.000040\n","Train Epoch: 0 [3904/6456 (60%)]\ttrain_Loss: 1.83289 \tval_Loss: 0.00000 time: 330.4351 \t lr:0.000039\n","Train Epoch: 0 [3936/6456 (61%)]\ttrain_Loss: 1.84822 \tval_Loss: 0.00000 time: 333.0636 \t lr:0.000039\n","Train Epoch: 0 [3968/6456 (61%)]\ttrain_Loss: 1.73905 \tval_Loss: 0.00000 time: 335.7157 \t lr:0.000038\n","Train Epoch: 0 [4000/6456 (62%)]\ttrain_Loss: 1.80511 \tval_Loss: 0.00000 time: 338.3879 \t lr:0.000038\n","Train Epoch: 0 [4032/6456 (62%)]\ttrain_Loss: 1.80377 \tval_Loss: 0.00000 time: 341.0415 \t lr:0.000037\n","Train Epoch: 0 [4064/6456 (63%)]\ttrain_Loss: 1.83847 \tval_Loss: 0.00000 time: 343.7269 \t lr:0.000037\n","Train Epoch: 0 [4096/6456 (63%)]\ttrain_Loss: 1.77437 \tval_Loss: 0.00000 time: 346.3821 \t lr:0.000036\n","Train Epoch: 0 [4128/6456 (64%)]\ttrain_Loss: 1.77344 \tval_Loss: 0.00000 time: 349.0457 \t lr:0.000036\n","Train Epoch: 0 [4160/6456 (64%)]\ttrain_Loss: 1.80205 \tval_Loss: 0.00000 time: 351.6880 \t lr:0.000036\n","Train Epoch: 0 [4192/6456 (65%)]\ttrain_Loss: 1.76586 \tval_Loss: 0.00000 time: 354.3307 \t lr:0.000035\n","Train Epoch: 0 [4224/6456 (65%)]\ttrain_Loss: 1.82237 \tval_Loss: 0.00000 time: 356.9823 \t lr:0.000035\n","Train Epoch: 0 [4256/6456 (66%)]\ttrain_Loss: 1.77029 \tval_Loss: 0.00000 time: 359.6113 \t lr:0.000034\n","Train Epoch: 0 [4288/6456 (66%)]\ttrain_Loss: 1.80576 \tval_Loss: 0.00000 time: 362.2501 \t lr:0.000034\n","Train Epoch: 0 [4320/6456 (67%)]\ttrain_Loss: 1.83425 \tval_Loss: 0.00000 time: 364.8769 \t lr:0.000033\n","Train Epoch: 0 [4352/6456 (67%)]\ttrain_Loss: 1.84318 \tval_Loss: 0.00000 time: 367.5191 \t lr:0.000033\n","Train Epoch: 0 [4384/6456 (68%)]\ttrain_Loss: 1.82066 \tval_Loss: 0.00000 time: 370.1599 \t lr:0.000032\n","Train Epoch: 0 [4416/6456 (68%)]\ttrain_Loss: 1.85095 \tval_Loss: 0.00000 time: 372.8002 \t lr:0.000032\n","Train Epoch: 0 [4448/6456 (69%)]\ttrain_Loss: 1.81917 \tval_Loss: 0.00000 time: 375.4226 \t lr:0.000031\n","Train Epoch: 0 [4480/6456 (69%)]\ttrain_Loss: 1.83070 \tval_Loss: 0.00000 time: 378.0705 \t lr:0.000031\n","Train Epoch: 0 [4512/6456 (70%)]\ttrain_Loss: 1.75994 \tval_Loss: 0.00000 time: 380.7154 \t lr:0.000030\n","Train Epoch: 0 [4544/6456 (70%)]\ttrain_Loss: 1.85275 \tval_Loss: 0.00000 time: 383.3533 \t lr:0.000030\n","Train Epoch: 0 [4576/6456 (71%)]\ttrain_Loss: 1.82771 \tval_Loss: 0.00000 time: 385.9930 \t lr:0.000029\n","Train Epoch: 0 [4608/6456 (71%)]\ttrain_Loss: 1.84161 \tval_Loss: 0.00000 time: 388.6258 \t lr:0.000029\n","Train Epoch: 0 [4640/6456 (72%)]\ttrain_Loss: 1.81907 \tval_Loss: 0.00000 time: 391.2680 \t lr:0.000028\n","Train Epoch: 0 [4672/6456 (72%)]\ttrain_Loss: 1.79513 \tval_Loss: 0.00000 time: 393.9064 \t lr:0.000028\n","Train Epoch: 0 [4704/6456 (73%)]\ttrain_Loss: 1.78392 \tval_Loss: 0.00000 time: 396.5495 \t lr:0.000027\n","Train Epoch: 0 [4736/6456 (73%)]\ttrain_Loss: 1.79107 \tval_Loss: 0.00000 time: 399.1888 \t lr:0.000027\n","Train Epoch: 0 [4768/6456 (74%)]\ttrain_Loss: 1.89193 \tval_Loss: 0.00000 time: 401.8184 \t lr:0.000026\n","Train Epoch: 0 [4800/6456 (74%)]\ttrain_Loss: 1.73483 \tval_Loss: 0.00000 time: 404.4549 \t lr:0.000026\n","Train Epoch: 0 [4832/6456 (75%)]\ttrain_Loss: 1.80989 \tval_Loss: 0.00000 time: 407.0860 \t lr:0.000025\n","Train Epoch: 0 [4864/6456 (75%)]\ttrain_Loss: 1.76507 \tval_Loss: 0.00000 time: 409.7579 \t lr:0.000025\n","Train Epoch: 0 [4896/6456 (76%)]\ttrain_Loss: 1.79743 \tval_Loss: 0.00000 time: 412.3859 \t lr:0.000024\n","Train Epoch: 0 [4928/6456 (76%)]\ttrain_Loss: 1.88603 \tval_Loss: 0.00000 time: 415.0150 \t lr:0.000024\n","Train Epoch: 0 [4960/6456 (77%)]\ttrain_Loss: 1.83282 \tval_Loss: 0.00000 time: 417.6319 \t lr:0.000023\n","Train Epoch: 0 [4992/6456 (77%)]\ttrain_Loss: 1.84721 \tval_Loss: 0.00000 time: 420.2594 \t lr:0.000023\n","Train Epoch: 0 [5024/6456 (78%)]\ttrain_Loss: 1.78649 \tval_Loss: 0.00000 time: 422.8898 \t lr:0.000022\n","Train Epoch: 0 [5056/6456 (78%)]\ttrain_Loss: 1.84204 \tval_Loss: 0.00000 time: 425.5001 \t lr:0.000022\n","Train Epoch: 0 [5088/6456 (79%)]\ttrain_Loss: 1.82028 \tval_Loss: 0.00000 time: 428.1274 \t lr:0.000021\n","Train Epoch: 0 [5120/6456 (79%)]\ttrain_Loss: 1.84367 \tval_Loss: 0.00000 time: 430.8012 \t lr:0.000021\n","Train Epoch: 0 [5152/6456 (80%)]\ttrain_Loss: 1.83103 \tval_Loss: 0.00000 time: 433.4356 \t lr:0.000020\n","Train Epoch: 0 [5184/6456 (80%)]\ttrain_Loss: 1.77298 \tval_Loss: 0.00000 time: 436.1027 \t lr:0.000020\n","Train Epoch: 0 [5216/6456 (81%)]\ttrain_Loss: 1.77694 \tval_Loss: 0.00000 time: 438.7311 \t lr:0.000019\n","Train Epoch: 0 [5248/6456 (81%)]\ttrain_Loss: 1.78803 \tval_Loss: 0.00000 time: 441.3516 \t lr:0.000019\n","Train Epoch: 0 [5280/6456 (82%)]\ttrain_Loss: 1.81064 \tval_Loss: 0.00000 time: 443.9873 \t lr:0.000018\n","Train Epoch: 0 [5312/6456 (82%)]\ttrain_Loss: 1.79460 \tval_Loss: 0.00000 time: 446.6355 \t lr:0.000018\n","Train Epoch: 0 [5344/6456 (83%)]\ttrain_Loss: 1.83220 \tval_Loss: 0.00000 time: 449.2898 \t lr:0.000017\n","Train Epoch: 0 [5376/6456 (83%)]\ttrain_Loss: 1.88068 \tval_Loss: 0.00000 time: 451.8973 \t lr:0.000017\n","Train Epoch: 0 [5408/6456 (84%)]\ttrain_Loss: 1.83435 \tval_Loss: 0.00000 time: 454.5230 \t lr:0.000016\n","Train Epoch: 0 [5440/6456 (84%)]\ttrain_Loss: 1.85816 \tval_Loss: 0.00000 time: 457.1659 \t lr:0.000016\n","Train Epoch: 0 [5472/6456 (85%)]\ttrain_Loss: 1.77123 \tval_Loss: 0.00000 time: 459.8274 \t lr:0.000015\n","Train Epoch: 0 [5504/6456 (85%)]\ttrain_Loss: 1.90096 \tval_Loss: 0.00000 time: 462.4796 \t lr:0.000015\n","Train Epoch: 0 [5536/6456 (86%)]\ttrain_Loss: 1.82151 \tval_Loss: 0.00000 time: 465.1525 \t lr:0.000014\n","Train Epoch: 0 [5568/6456 (86%)]\ttrain_Loss: 1.80711 \tval_Loss: 0.00000 time: 467.7810 \t lr:0.000014\n","Train Epoch: 0 [5600/6456 (87%)]\ttrain_Loss: 1.87508 \tval_Loss: 0.00000 time: 470.4062 \t lr:0.000013\n","Train Epoch: 0 [5632/6456 (87%)]\ttrain_Loss: 1.80887 \tval_Loss: 0.00000 time: 473.0571 \t lr:0.000013\n","Train Epoch: 0 [5664/6456 (88%)]\ttrain_Loss: 1.82313 \tval_Loss: 0.00000 time: 475.7197 \t lr:0.000012\n","Train Epoch: 0 [5696/6456 (88%)]\ttrain_Loss: 1.82964 \tval_Loss: 0.00000 time: 478.3635 \t lr:0.000012\n","Train Epoch: 0 [5728/6456 (89%)]\ttrain_Loss: 1.82111 \tval_Loss: 0.00000 time: 481.0256 \t lr:0.000011\n","Train Epoch: 0 [5760/6456 (89%)]\ttrain_Loss: 1.80092 \tval_Loss: 0.00000 time: 483.6619 \t lr:0.000011\n","Train Epoch: 0 [5792/6456 (90%)]\ttrain_Loss: 1.79105 \tval_Loss: 0.00000 time: 486.2876 \t lr:0.000010\n","Train Epoch: 0 [5824/6456 (90%)]\ttrain_Loss: 1.78121 \tval_Loss: 0.00000 time: 488.9269 \t lr:0.000010\n","Train Epoch: 0 [5856/6456 (91%)]\ttrain_Loss: 1.83875 \tval_Loss: 0.00000 time: 491.5790 \t lr:0.000009\n","Train Epoch: 0 [5888/6456 (91%)]\ttrain_Loss: 1.83274 \tval_Loss: 0.00000 time: 494.2244 \t lr:0.000009\n","Train Epoch: 0 [5920/6456 (92%)]\ttrain_Loss: 1.82018 \tval_Loss: 0.00000 time: 496.8569 \t lr:0.000008\n","Train Epoch: 0 [5952/6456 (92%)]\ttrain_Loss: 1.77484 \tval_Loss: 0.00000 time: 499.4806 \t lr:0.000008\n","Train Epoch: 0 [5984/6456 (93%)]\ttrain_Loss: 1.77909 \tval_Loss: 0.00000 time: 502.1221 \t lr:0.000007\n","Train Epoch: 0 [6016/6456 (93%)]\ttrain_Loss: 1.75046 \tval_Loss: 0.00000 time: 504.7838 \t lr:0.000007\n","Train Epoch: 0 [6048/6456 (94%)]\ttrain_Loss: 1.82050 \tval_Loss: 0.00000 time: 507.4462 \t lr:0.000006\n","Train Epoch: 0 [6080/6456 (94%)]\ttrain_Loss: 1.82794 \tval_Loss: 0.00000 time: 510.1035 \t lr:0.000006\n","Train Epoch: 0 [6112/6456 (95%)]\ttrain_Loss: 1.75528 \tval_Loss: 0.00000 time: 512.7533 \t lr:0.000005\n","Train Epoch: 0 [6144/6456 (95%)]\ttrain_Loss: 1.81707 \tval_Loss: 0.00000 time: 515.3988 \t lr:0.000005\n","Train Epoch: 0 [6176/6456 (96%)]\ttrain_Loss: 1.82018 \tval_Loss: 0.00000 time: 518.0754 \t lr:0.000004\n","Train Epoch: 0 [6208/6456 (96%)]\ttrain_Loss: 1.78566 \tval_Loss: 0.00000 time: 520.7481 \t lr:0.000004\n","Train Epoch: 0 [6240/6456 (97%)]\ttrain_Loss: 1.77846 \tval_Loss: 0.00000 time: 523.4147 \t lr:0.000003\n","Train Epoch: 0 [6272/6456 (97%)]\ttrain_Loss: 1.79276 \tval_Loss: 0.00000 time: 526.0809 \t lr:0.000003\n","Train Epoch: 0 [6304/6456 (98%)]\ttrain_Loss: 1.81165 \tval_Loss: 0.00000 time: 528.7312 \t lr:0.000002\n","Train Epoch: 0 [6336/6456 (98%)]\ttrain_Loss: 1.82264 \tval_Loss: 0.00000 time: 531.3988 \t lr:0.000002\n","Train Epoch: 0 [6368/6456 (99%)]\ttrain_Loss: 1.81057 \tval_Loss: 0.00000 time: 534.0668 \t lr:0.000001\n","Train Epoch: 0 [6400/6456 (99%)]\ttrain_Loss: 1.81434 \tval_Loss: 0.00000 time: 536.7047 \t lr:0.000001\n","Train Epoch: 0 [6432/6456 (100%)]\ttrain_Loss: 1.74346 \tval_Loss: 0.00000 time: 539.3756 \t lr:0.000000\n","Val_loss: tensor(7.4042, device='cuda:0')\n","update!!!!!!!!!!!!\n"]}]},{"cell_type":"markdown","source":["**************** STOPPED HERE - NEED TO RE FORMAT NER / RE DATA****************"],"metadata":{"id":"Kq0EEGT7fOEJ"}},{"cell_type":"code","source":["!python /content/drive/MyDrive/GitHub/exBERT/Finetuning_NER.py -e 1 -b 2 -sp /content/drive/MyDrive/GitHub/exBERT/PubMED_train_files/NER -dv 0 -lr 1e-04 -str exBERT -config /content/drive/MyDrive/GitHub/exBERT/PubMED_train_files/PubMed/config.json /content/drive/MyDrive/GitHub/exBERT/PubMED_train_files/PubMed/pubmed_config_ex_base_s3.json -vocab /content/drive/MyDrive/GitHub/exBERT/PubMED_train_files/PubMed/vocab.txt -pm_p /content/drive/MyDrive/GitHub/exBERT/PubMED_train_files/PubMed/pytorch_model.bin -dp /content/drive/MyDrive/GitHub/exBERT/ner_sample_data/ -tln 6 7 8 9 10 11 12\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9ZAnqpHbQaM2","executionInfo":{"status":"ok","timestamp":1648475935937,"user_tz":-60,"elapsed":58736,"user":{"displayName":"Lya Solis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0zQkkPA02m_TCbUFh15I5DgeImYkaFOwSePgp=s64","userId":"00474828135331575492"}},"outputId":"af4265b4-c152-42d4-bbd6-a57b345881b6"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n","{'epochs': 1, 'batchsize': 2, 'save_path': '/content/drive/MyDrive/GitHub/exBERT/PubMED_train_files/NER', 'device': [0], 'learning_rate': 0.0001, 'strategy': 'exBERT', 'config': ['/content/drive/MyDrive/GitHub/exBERT/PubMED_train_files/PubMed/config.json', '/content/drive/MyDrive/GitHub/exBERT/PubMED_train_files/PubMed/pubmed_config_ex_base_s3.json'], 'vocab': '/content/drive/MyDrive/GitHub/exBERT/PubMED_train_files/PubMed/vocab.txt', 'pretrained_model_path': '/content/drive/MyDrive/GitHub/exBERT/PubMED_train_files/PubMed/pytorch_model.bin', 'data_path': '/content/drive/MyDrive/GitHub/exBERT/ner_sample_data/', 'train_layer_number': ['6', '7', '8', '9', '10', '11', '12']}\n","[0]\n","load file: /content/drive/MyDrive/GitHub/exBERT/ner_sample_data/train.txt\n","seprate sentence\n","tokenization\n","error num:0\n","complete\n","load file: /content/drive/MyDrive/GitHub/exBERT/ner_sample_data/dev.txt\n","seprate sentence\n","tokenization\n","error num:0\n","complete\n","load file: /content/drive/MyDrive/GitHub/exBERT/ner_sample_data/test.txt\n","seprate sentence\n","tokenization\n","error num:0\n","complete\n","Building PyTorch model from configuration: {\n","  \"_name_or_path\": \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.17.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","Building PyTorch model from configuration: {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 4655\n","}\n","\n","bert.encoder.layer.6.attention.self.query.weight\n","bert.encoder.layer.6.attention.self.query.bias\n","bert.encoder.layer.6.attention.self.key.weight\n","bert.encoder.layer.6.attention.self.key.bias\n","bert.encoder.layer.6.attention.self.value.weight\n","bert.encoder.layer.6.attention.self.value.bias\n","bert.encoder.layer.6.attention.output.dense.weight\n","bert.encoder.layer.6.attention.output.dense.bias\n","bert.encoder.layer.6.attention.output.LayerNorm.weight\n","bert.encoder.layer.6.attention.output.LayerNorm.bias\n","bert.encoder.layer.6.intermediate.dense.weight\n","bert.encoder.layer.6.intermediate.dense.bias\n","bert.encoder.layer.6.output.dense.weight\n","bert.encoder.layer.6.output.dense.bias\n","bert.encoder.layer.6.output.LayerNorm.weight\n","bert.encoder.layer.6.output.LayerNorm.bias\n","bert.encoder.layer.6.attention_ADD.self.query.weight\n","bert.encoder.layer.6.attention_ADD.self.query.bias\n","bert.encoder.layer.6.attention_ADD.self.key.weight\n","bert.encoder.layer.6.attention_ADD.self.key.bias\n","bert.encoder.layer.6.attention_ADD.self.value.weight\n","bert.encoder.layer.6.attention_ADD.self.value.bias\n","bert.encoder.layer.6.attention_ADD.output.dense.weight\n","bert.encoder.layer.6.attention_ADD.output.dense.bias\n","bert.encoder.layer.6.attention_ADD.output.LayerNorm.weight\n","bert.encoder.layer.6.attention_ADD.output.LayerNorm.bias\n","bert.encoder.layer.6.intermediate_ADD.dense.weight\n","bert.encoder.layer.6.intermediate_ADD.dense.bias\n","bert.encoder.layer.6.output_ADD.dense.weight\n","bert.encoder.layer.6.output_ADD.dense.bias\n","bert.encoder.layer.6.output_ADD.LayerNorm.weight\n","bert.encoder.layer.6.output_ADD.LayerNorm.bias\n","bert.encoder.layer.6.gate_ADD.weight\n","bert.encoder.layer.6.gate_ADD.bias\n","bert.encoder.layer.7.attention.self.query.weight\n","bert.encoder.layer.7.attention.self.query.bias\n","bert.encoder.layer.7.attention.self.key.weight\n","bert.encoder.layer.7.attention.self.key.bias\n","bert.encoder.layer.7.attention.self.value.weight\n","bert.encoder.layer.7.attention.self.value.bias\n","bert.encoder.layer.7.attention.output.dense.weight\n","bert.encoder.layer.7.attention.output.dense.bias\n","bert.encoder.layer.7.attention.output.LayerNorm.weight\n","bert.encoder.layer.7.attention.output.LayerNorm.bias\n","bert.encoder.layer.7.intermediate.dense.weight\n","bert.encoder.layer.7.intermediate.dense.bias\n","bert.encoder.layer.7.output.dense.weight\n","bert.encoder.layer.7.output.dense.bias\n","bert.encoder.layer.7.output.LayerNorm.weight\n","bert.encoder.layer.7.output.LayerNorm.bias\n","bert.encoder.layer.7.attention_ADD.self.query.weight\n","bert.encoder.layer.7.attention_ADD.self.query.bias\n","bert.encoder.layer.7.attention_ADD.self.key.weight\n","bert.encoder.layer.7.attention_ADD.self.key.bias\n","bert.encoder.layer.7.attention_ADD.self.value.weight\n","bert.encoder.layer.7.attention_ADD.self.value.bias\n","bert.encoder.layer.7.attention_ADD.output.dense.weight\n","bert.encoder.layer.7.attention_ADD.output.dense.bias\n","bert.encoder.layer.7.attention_ADD.output.LayerNorm.weight\n","bert.encoder.layer.7.attention_ADD.output.LayerNorm.bias\n","bert.encoder.layer.7.intermediate_ADD.dense.weight\n","bert.encoder.layer.7.intermediate_ADD.dense.bias\n","bert.encoder.layer.7.output_ADD.dense.weight\n","bert.encoder.layer.7.output_ADD.dense.bias\n","bert.encoder.layer.7.output_ADD.LayerNorm.weight\n","bert.encoder.layer.7.output_ADD.LayerNorm.bias\n","bert.encoder.layer.7.gate_ADD.weight\n","bert.encoder.layer.7.gate_ADD.bias\n","bert.encoder.layer.8.attention.self.query.weight\n","bert.encoder.layer.8.attention.self.query.bias\n","bert.encoder.layer.8.attention.self.key.weight\n","bert.encoder.layer.8.attention.self.key.bias\n","bert.encoder.layer.8.attention.self.value.weight\n","bert.encoder.layer.8.attention.self.value.bias\n","bert.encoder.layer.8.attention.output.dense.weight\n","bert.encoder.layer.8.attention.output.dense.bias\n","bert.encoder.layer.8.attention.output.LayerNorm.weight\n","bert.encoder.layer.8.attention.output.LayerNorm.bias\n","bert.encoder.layer.8.intermediate.dense.weight\n","bert.encoder.layer.8.intermediate.dense.bias\n","bert.encoder.layer.8.output.dense.weight\n","bert.encoder.layer.8.output.dense.bias\n","bert.encoder.layer.8.output.LayerNorm.weight\n","bert.encoder.layer.8.output.LayerNorm.bias\n","bert.encoder.layer.8.attention_ADD.self.query.weight\n","bert.encoder.layer.8.attention_ADD.self.query.bias\n","bert.encoder.layer.8.attention_ADD.self.key.weight\n","bert.encoder.layer.8.attention_ADD.self.key.bias\n","bert.encoder.layer.8.attention_ADD.self.value.weight\n","bert.encoder.layer.8.attention_ADD.self.value.bias\n","bert.encoder.layer.8.attention_ADD.output.dense.weight\n","bert.encoder.layer.8.attention_ADD.output.dense.bias\n","bert.encoder.layer.8.attention_ADD.output.LayerNorm.weight\n","bert.encoder.layer.8.attention_ADD.output.LayerNorm.bias\n","bert.encoder.layer.8.intermediate_ADD.dense.weight\n","bert.encoder.layer.8.intermediate_ADD.dense.bias\n","bert.encoder.layer.8.output_ADD.dense.weight\n","bert.encoder.layer.8.output_ADD.dense.bias\n","bert.encoder.layer.8.output_ADD.LayerNorm.weight\n","bert.encoder.layer.8.output_ADD.LayerNorm.bias\n","bert.encoder.layer.8.gate_ADD.weight\n","bert.encoder.layer.8.gate_ADD.bias\n","bert.encoder.layer.9.attention.self.query.weight\n","bert.encoder.layer.9.attention.self.query.bias\n","bert.encoder.layer.9.attention.self.key.weight\n","bert.encoder.layer.9.attention.self.key.bias\n","bert.encoder.layer.9.attention.self.value.weight\n","bert.encoder.layer.9.attention.self.value.bias\n","bert.encoder.layer.9.attention.output.dense.weight\n","bert.encoder.layer.9.attention.output.dense.bias\n","bert.encoder.layer.9.attention.output.LayerNorm.weight\n","bert.encoder.layer.9.attention.output.LayerNorm.bias\n","bert.encoder.layer.9.intermediate.dense.weight\n","bert.encoder.layer.9.intermediate.dense.bias\n","bert.encoder.layer.9.output.dense.weight\n","bert.encoder.layer.9.output.dense.bias\n","bert.encoder.layer.9.output.LayerNorm.weight\n","bert.encoder.layer.9.output.LayerNorm.bias\n","bert.encoder.layer.9.attention_ADD.self.query.weight\n","bert.encoder.layer.9.attention_ADD.self.query.bias\n","bert.encoder.layer.9.attention_ADD.self.key.weight\n","bert.encoder.layer.9.attention_ADD.self.key.bias\n","bert.encoder.layer.9.attention_ADD.self.value.weight\n","bert.encoder.layer.9.attention_ADD.self.value.bias\n","bert.encoder.layer.9.attention_ADD.output.dense.weight\n","bert.encoder.layer.9.attention_ADD.output.dense.bias\n","bert.encoder.layer.9.attention_ADD.output.LayerNorm.weight\n","bert.encoder.layer.9.attention_ADD.output.LayerNorm.bias\n","bert.encoder.layer.9.intermediate_ADD.dense.weight\n","bert.encoder.layer.9.intermediate_ADD.dense.bias\n","bert.encoder.layer.9.output_ADD.dense.weight\n","bert.encoder.layer.9.output_ADD.dense.bias\n","bert.encoder.layer.9.output_ADD.LayerNorm.weight\n","bert.encoder.layer.9.output_ADD.LayerNorm.bias\n","bert.encoder.layer.9.gate_ADD.weight\n","bert.encoder.layer.9.gate_ADD.bias\n","bert.encoder.layer.10.attention.self.query.weight\n","bert.encoder.layer.10.attention.self.query.bias\n","bert.encoder.layer.10.attention.self.key.weight\n","bert.encoder.layer.10.attention.self.key.bias\n","bert.encoder.layer.10.attention.self.value.weight\n","bert.encoder.layer.10.attention.self.value.bias\n","bert.encoder.layer.10.attention.output.dense.weight\n","bert.encoder.layer.10.attention.output.dense.bias\n","bert.encoder.layer.10.attention.output.LayerNorm.weight\n","bert.encoder.layer.10.attention.output.LayerNorm.bias\n","bert.encoder.layer.10.intermediate.dense.weight\n","bert.encoder.layer.10.intermediate.dense.bias\n","bert.encoder.layer.10.output.dense.weight\n","bert.encoder.layer.10.output.dense.bias\n","bert.encoder.layer.10.output.LayerNorm.weight\n","bert.encoder.layer.10.output.LayerNorm.bias\n","bert.encoder.layer.10.attention_ADD.self.query.weight\n","bert.encoder.layer.10.attention_ADD.self.query.bias\n","bert.encoder.layer.10.attention_ADD.self.key.weight\n","bert.encoder.layer.10.attention_ADD.self.key.bias\n","bert.encoder.layer.10.attention_ADD.self.value.weight\n","bert.encoder.layer.10.attention_ADD.self.value.bias\n","bert.encoder.layer.10.attention_ADD.output.dense.weight\n","bert.encoder.layer.10.attention_ADD.output.dense.bias\n","bert.encoder.layer.10.attention_ADD.output.LayerNorm.weight\n","bert.encoder.layer.10.attention_ADD.output.LayerNorm.bias\n","bert.encoder.layer.10.intermediate_ADD.dense.weight\n","bert.encoder.layer.10.intermediate_ADD.dense.bias\n","bert.encoder.layer.10.output_ADD.dense.weight\n","bert.encoder.layer.10.output_ADD.dense.bias\n","bert.encoder.layer.10.output_ADD.LayerNorm.weight\n","bert.encoder.layer.10.output_ADD.LayerNorm.bias\n","bert.encoder.layer.10.gate_ADD.weight\n","bert.encoder.layer.10.gate_ADD.bias\n","bert.encoder.layer.11.attention.self.query.weight\n","bert.encoder.layer.11.attention.self.query.bias\n","bert.encoder.layer.11.attention.self.key.weight\n","bert.encoder.layer.11.attention.self.key.bias\n","bert.encoder.layer.11.attention.self.value.weight\n","bert.encoder.layer.11.attention.self.value.bias\n","bert.encoder.layer.11.attention.output.dense.weight\n","bert.encoder.layer.11.attention.output.dense.bias\n","bert.encoder.layer.11.attention.output.LayerNorm.weight\n","bert.encoder.layer.11.attention.output.LayerNorm.bias\n","bert.encoder.layer.11.intermediate.dense.weight\n","bert.encoder.layer.11.intermediate.dense.bias\n","bert.encoder.layer.11.output.dense.weight\n","bert.encoder.layer.11.output.dense.bias\n","bert.encoder.layer.11.output.LayerNorm.weight\n","bert.encoder.layer.11.output.LayerNorm.bias\n","bert.encoder.layer.11.attention_ADD.self.query.weight\n","bert.encoder.layer.11.attention_ADD.self.query.bias\n","bert.encoder.layer.11.attention_ADD.self.key.weight\n","bert.encoder.layer.11.attention_ADD.self.key.bias\n","bert.encoder.layer.11.attention_ADD.self.value.weight\n","bert.encoder.layer.11.attention_ADD.self.value.bias\n","bert.encoder.layer.11.attention_ADD.output.dense.weight\n","bert.encoder.layer.11.attention_ADD.output.dense.bias\n","bert.encoder.layer.11.attention_ADD.output.LayerNorm.weight\n","bert.encoder.layer.11.attention_ADD.output.LayerNorm.bias\n","bert.encoder.layer.11.intermediate_ADD.dense.weight\n","bert.encoder.layer.11.intermediate_ADD.dense.bias\n","bert.encoder.layer.11.output_ADD.dense.weight\n","bert.encoder.layer.11.output_ADD.dense.bias\n","bert.encoder.layer.11.output_ADD.LayerNorm.weight\n","bert.encoder.layer.11.output_ADD.LayerNorm.bias\n","bert.encoder.layer.11.gate_ADD.weight\n","bert.encoder.layer.11.gate_ADD.bias\n","bert.pooler.dense.weight\n","bert.pooler.dense.bias\n","classifier.weight\n","classifier.bias\n","/content/drive/MyDrive/GitHub/exBERT/exBERT/optimization.py:133: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)\n","  next_m.mul_(beta1).add_(1 - beta1, grad)\n","Train Epoch: 0 [20/374 (5%)]\ttrain_Loss: 1.20259 \tval_Loss: 1.12277                 \t train_acc:0.657 \tval_acc:0.741 \ttf1: 0.197\tvf1: 0.229 time: 2.09 \tlr:0.000100\n","Train Epoch: 0 [40/374 (11%)]\ttrain_Loss: 0.37970 \tval_Loss: 0.28411                 \t train_acc:0.827 \tval_acc:0.888 \ttf1: 0.304\tvf1: 0.316 time: 3.96 \tlr:0.000100\n","Train Epoch: 0 [60/374 (16%)]\ttrain_Loss: 0.42223 \tval_Loss: 0.32861                 \t train_acc:0.814 \tval_acc:0.835 \ttf1: 0.310\tvf1: 0.271 time: 5.83 \tlr:0.000100\n","Train Epoch: 0 [80/374 (21%)]\ttrain_Loss: 0.32857 \tval_Loss: 0.30414                 \t train_acc:0.842 \tval_acc:0.853 \ttf1: 0.262\tvf1: 0.300 time: 7.71 \tlr:0.000100\n","Train Epoch: 0 [100/374 (27%)]\ttrain_Loss: 0.38219 \tval_Loss: 0.36601                 \t train_acc:0.813 \tval_acc:0.811 \ttf1: 0.244\tvf1: 0.270 time: 9.58 \tlr:0.000100\n","Train Epoch: 0 [120/374 (32%)]\ttrain_Loss: 0.32691 \tval_Loss: 0.29025                 \t train_acc:0.837 \tval_acc:0.865 \ttf1: 0.321\tvf1: 0.274 time: 11.45 \tlr:0.000100\n","Train Epoch: 0 [140/374 (37%)]\ttrain_Loss: 0.29680 \tval_Loss: 0.26899                 \t train_acc:0.864 \tval_acc:0.861 \ttf1: 0.279\tvf1: 0.394 time: 13.34 \tlr:0.000100\n","Train Epoch: 0 [160/374 (43%)]\ttrain_Loss: 0.50029 \tval_Loss: 0.36221                 \t train_acc:0.761 \tval_acc:0.820 \ttf1: 0.218\tvf1: 0.320 time: 15.20 \tlr:0.000100\n","Train Epoch: 0 [180/374 (48%)]\ttrain_Loss: 0.42114 \tval_Loss: 0.34398                 \t train_acc:0.809 \tval_acc:0.848 \ttf1: 0.305\tvf1: 0.325 time: 17.07 \tlr:0.000100\n","Train Epoch: 0 [200/374 (53%)]\ttrain_Loss: 0.38252 \tval_Loss: 0.26525                 \t train_acc:0.817 \tval_acc:0.884 \ttf1: 0.240\tvf1: 0.342 time: 18.95 \tlr:0.000100\n","Train Epoch: 0 [220/374 (59%)]\ttrain_Loss: 0.32145 \tval_Loss: 0.43353                 \t train_acc:0.845 \tval_acc:0.757 \ttf1: 0.347\tvf1: 0.257 time: 20.82 \tlr:0.000100\n","Train Epoch: 0 [240/374 (64%)]\ttrain_Loss: 0.32514 \tval_Loss: 0.32138                 \t train_acc:0.853 \tval_acc:0.836 \ttf1: 0.278\tvf1: 0.312 time: 22.71 \tlr:0.000100\n","Train Epoch: 0 [260/374 (70%)]\ttrain_Loss: 0.42694 \tval_Loss: 0.28507                 \t train_acc:0.797 \tval_acc:0.864 \ttf1: 0.360\tvf1: 0.304 time: 24.59 \tlr:0.000100\n","Train Epoch: 0 [280/374 (75%)]\ttrain_Loss: 0.29856 \tval_Loss: 0.34964                 \t train_acc:0.867 \tval_acc:0.839 \ttf1: 0.342\tvf1: 0.338 time: 26.47 \tlr:0.000100\n","Train Epoch: 0 [300/374 (80%)]\ttrain_Loss: 0.38153 \tval_Loss: 0.34446                 \t train_acc:0.821 \tval_acc:0.844 \ttf1: 0.304\tvf1: 0.318 time: 28.34 \tlr:0.000100\n","Train Epoch: 0 [320/374 (86%)]\ttrain_Loss: 0.31790 \tval_Loss: 0.37101                 \t train_acc:0.851 \tval_acc:0.809 \ttf1: 0.298\tvf1: 0.362 time: 30.22 \tlr:0.000100\n","Train Epoch: 0 [340/374 (91%)]\ttrain_Loss: 0.34105 \tval_Loss: 0.35614                 \t train_acc:0.831 \tval_acc:0.811 \ttf1: 0.265\tvf1: 0.270 time: 32.09 \tlr:0.000100\n","Train Epoch: 0 [360/374 (96%)]\ttrain_Loss: 0.34830 \tval_Loss: 0.25502                 \t train_acc:0.820 \tval_acc:0.870 \ttf1: 0.277\tvf1: 0.309 time: 33.96 \tlr:0.000100\n","VAL  F1:0.1808802456499488\n","update!!!!!!!!!!!!\n","TEST  F1:0.18584884994523548\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"s9jGr4txQfL5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"nEom5bNFQfJQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"VD2n3uYjQfGs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python bert/create_pretraining_data.py --input_file=/content/drive/MyDrive/GitHub/exBERT/data/train_data.txt --output_file=/content/drive/MyDrive/GitHub/exBERT/PubMED_train_files/pubmed_uncased_train_data.tfrecord --vocab_file=/content/drive/MyDrive/GitHub/exBERT/PubMED_train_files/PubMed/vocab.txt --do_lower_case=True --max_seq_length=512 --max_predictions_per_seq=20 --masked_lm_prob=0.15 --random_seed=12345 --dupe_factor=5\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QRRdhPogFJ1k","executionInfo":{"status":"ok","timestamp":1648448166129,"user_tz":-60,"elapsed":2506,"user":{"displayName":"Lya Solis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0zQkkPA02m_TCbUFh15I5DgeImYkaFOwSePgp=s64","userId":"00474828135331575492"}},"outputId":"1e6cfe65-dbcc-48e4-ff3b-0e2e72a62569"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"bert/create_pretraining_data.py\", line 24, in <module>\n","    from bert import tokenization\n","ModuleNotFoundError: No module named 'bert'\n"]}]},{"cell_type":"markdown","source":["https://medium.com/@manasmohanty/ncbi-bluebert-ncbi-bert-using-tensorflow-weights-with-huggingface-transformers-15a7ec27fc3d"],"metadata":{"id":"vNLx5UHkEk_Z"}},{"cell_type":"markdown","source":["We used the following code to train the BERT model. Please do not include init_checkpoint if you are pre-training from scratch. Please see https://github.com/google-research/bert for more details."],"metadata":{"id":"nMr5OpPvhSVk"}},{"cell_type":"code","source":["python bert/run_pretraining.py \\\n","  --input_file=pubmed_uncased_sentence_nltk.tfrecord \\\n","  --output_dir=$BlueBERT_DIR \\\n","  --do_train=True \\\n","  --do_eval=True \\\n","  --bert_config_file=$BlueBERT_DIR/bert_config.json \\\n","  --init_checkpoint=$BlueBERT_DIR/bert_model.ckpt \\\n","  --train_batch_size=32 \\\n","  --max_seq_length=128 \\\n","  --max_predictions_per_seq=20 \\\n","  --num_train_steps=20000 \\\n","  --num_warmup_steps=10 \\\n","  --learning_rate=2e-5"],"metadata":{"id":"vUw5WewxgzNg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"CWX4y94ygzQX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"sdFEO9-igzVm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"iPXY_Jz6gzYt"},"execution_count":null,"outputs":[]}]}