{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of 3_pretraining.ipynb","provenance":[{"file_id":"1u4jvMyDUKv7qIL0hEO6jOXMwaJhXWnAm","timestamp":1648472838036}],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyN5Hcqx2UC66Fy3UFNN6PqY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["### Pre-training with BERT"],"metadata":{"id":"URLWQqrqgzh4"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"yqnTtgv_gujL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648470929413,"user_tz":-60,"elapsed":15483,"user":{"displayName":"Lya Solis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0zQkkPA02m_TCbUFh15I5DgeImYkaFOwSePgp=s64","userId":"00474828135331575492"}},"outputId":"5f13033b-a0fe-4fb7-8fbf-eea9497998fc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!ls /content/drive/MyDrive/GitHub/"],"metadata":{"id":"mpiJgx6VR6p_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648470931176,"user_tz":-60,"elapsed":267,"user":{"displayName":"Lya Solis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0zQkkPA02m_TCbUFh15I5DgeImYkaFOwSePgp=s64","userId":"00474828135331575492"}},"outputId":"d98fde40-134c-41e9-ee82-2a1b9ee64106"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["bc5cdr-ner  exBERT\n","bluebert    nd00333_AZMLND_Optimizing_a_Pipeline_in_Azure-Starter_Files\n"]}]},{"cell_type":"code","source":["import shutil\n","shutil.copytree(\"/content/drive/MyDrive/GitHub/exBERT/exBERT\", \"./exBERT\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"BKj02H6MNTOC","executionInfo":{"status":"ok","timestamp":1648470947061,"user_tz":-60,"elapsed":14474,"user":{"displayName":"Lya Solis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0zQkkPA02m_TCbUFh15I5DgeImYkaFOwSePgp=s64","userId":"00474828135331575492"}},"outputId":"6541653a-e4b3-40ad-dba7-4032519232bd"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'./exBERT'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["!pip install transformers\n","!pip install tokenizers"],"metadata":{"id":"beeWTOuRgzLR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648470958122,"user_tz":-60,"elapsed":10157,"user":{"displayName":"Lya Solis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0zQkkPA02m_TCbUFh15I5DgeImYkaFOwSePgp=s64","userId":"00474828135331575492"}},"outputId":"b1308d52-fca9-4ca0-f7cf-42aed62dbbcf"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 7.1 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 6.0 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 66.1 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 67.1 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Collecting tokenizers!=0.11.3,>=0.11.1\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 76.1 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0\n","Requirement already satisfied: tokenizers in /usr/local/lib/python3.7/dist-packages (0.11.6)\n"]}]},{"cell_type":"code","source":["!pip install boto3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nEtVVtqKQydv","executionInfo":{"status":"ok","timestamp":1648470965492,"user_tz":-60,"elapsed":7374,"user":{"displayName":"Lya Solis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0zQkkPA02m_TCbUFh15I5DgeImYkaFOwSePgp=s64","userId":"00474828135331575492"}},"outputId":"f0b73c97-b5b2-4c9c-d1af-f81497847868"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting boto3\n","  Downloading boto3-1.21.27-py3-none-any.whl (132 kB)\n","\u001b[?25l\r\u001b[K     |██▌                             | 10 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |█████                           | 20 kB 38.3 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 30 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 40 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 51 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 61 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 71 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 81 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 92 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 102 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 112 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 122 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 132 kB 8.1 MB/s \n","\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n","  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n","Collecting s3transfer<0.6.0,>=0.5.0\n","  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 10.2 MB/s \n","\u001b[?25hCollecting botocore<1.25.0,>=1.24.27\n","  Downloading botocore-1.24.27-py3-none-any.whl (8.6 MB)\n","\u001b[K     |████████████████████████████████| 8.6 MB 69.9 MB/s \n","\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n","  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 81.8 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.27->boto3) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.27->boto3) (1.15.0)\n","Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.9 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed boto3-1.21.27 botocore-1.24.27 jmespath-1.0.0 s3transfer-0.5.2 urllib3-1.26.9\n"]}]},{"cell_type":"code","source":["!pip install datasets git+https://github.com/huggingface/transformers/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tf0USlQyRK5J","executionInfo":{"status":"ok","timestamp":1648470993651,"user_tz":-60,"elapsed":28164,"user":{"displayName":"Lya Solis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0zQkkPA02m_TCbUFh15I5DgeImYkaFOwSePgp=s64","userId":"00474828135331575492"}},"outputId":"51647aaf-8587-454a-f17d-eb67204d1417"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/huggingface/transformers/\n","  Cloning https://github.com/huggingface/transformers/ to /tmp/pip-req-build-fug7e0si\n","  Running command git clone -q https://github.com/huggingface/transformers/ /tmp/pip-req-build-fug7e0si\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Collecting datasets\n","  Downloading datasets-2.0.0-py3-none-any.whl (325 kB)\n","\u001b[K     |████████████████████████████████| 325 kB 9.0 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (3.6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (1.21.5)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (2019.12.20)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (4.11.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (21.3)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (0.0.49)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (2.23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (6.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (0.4.0)\n","Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (0.11.6)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0.dev0) (4.63.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0.dev0) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.18.0.dev0) (3.0.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Collecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 72.2 MB/s \n","\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 59.9 MB/s \n","\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Collecting fsspec[http]>=2021.05.0\n","  Downloading fsspec-2022.2.0-py3-none-any.whl (134 kB)\n","\u001b[K     |████████████████████████████████| 134 kB 81.4 MB/s \n","\u001b[?25hCollecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.18.0.dev0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.18.0.dev0) (3.0.4)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 76.8 MB/s \n","\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.18.0.dev0) (2021.10.8)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 4.4 MB/s \n","\u001b[?25hCollecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 79.3 MB/s \n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 60.7 MB/s \n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Collecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.18.0.dev0) (3.7.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.18.0.dev0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.18.0.dev0) (1.1.0)\n","Building wheels for collected packages: transformers\n","  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transformers: filename=transformers-4.18.0.dev0-py3-none-any.whl size=3926086 sha256=baa0659f4a4a6d5654e3918797514986f009342020462441f56024ecdc3b2107\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-ete82ceq/wheels/fb/1b/91/0fcf504c386d427d65bbaf663eadf8e18cbf9795394ed7050d\n","Successfully built transformers\n","Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xxhash, responses, transformers, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.26.9\n","    Uninstalling urllib3-1.26.9:\n","      Successfully uninstalled urllib3-1.26.9\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.17.0\n","    Uninstalling transformers-4.17.0:\n","      Successfully uninstalled transformers-4.17.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.0.0 frozenlist-1.3.0 fsspec-2022.2.0 multidict-6.0.2 responses-0.18.0 transformers-4.18.0.dev0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n"]}]},{"cell_type":"code","source":["!pip install torch torchvision tensorflow\n","!pip install pytorch-pretrained-bert pandas"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gjcfLHl6SZvO","executionInfo":{"status":"ok","timestamp":1648471001119,"user_tz":-60,"elapsed":7487,"user":{"displayName":"Lya Solis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0zQkkPA02m_TCbUFh15I5DgeImYkaFOwSePgp=s64","userId":"00474828135331575492"}},"outputId":"65837dcd-983c-4b66-8f25-86d155e743bf"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n","Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.5)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n","Collecting tf-estimator-nightly==2.8.0.dev2021122109\n","  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n","\u001b[K     |████████████████████████████████| 462 kB 7.4 MB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (13.0.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.24.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n","Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.44.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.7.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.25.11)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n","Installing collected packages: tf-estimator-nightly\n","Successfully installed tf-estimator-nightly-2.8.0.dev2021122109\n","Collecting pytorch-pretrained-bert\n","  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n","\u001b[K     |████████████████████████████████| 123 kB 7.3 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (4.63.0)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.21.27)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.21.5)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.10.0+cu111)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.10.0.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n","Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (0.5.2)\n","Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (1.0.0)\n","Requirement already satisfied: botocore<1.25.0,>=1.24.27 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (1.24.27)\n","Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.27->boto3->pytorch-pretrained-bert) (1.25.11)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2021.10.8)\n","Installing collected packages: pytorch-pretrained-bert\n","Successfully installed pytorch-pretrained-bert-0.6.2\n"]}]},{"cell_type":"code","source":["!ls /content/drive/MyDrive/GitHub/exBERT/PubMED_train_files/PubMed"],"metadata":{"id":"040v3lVjSPW0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648471001448,"user_tz":-60,"elapsed":350,"user":{"displayName":"Lya Solis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0zQkkPA02m_TCbUFh15I5DgeImYkaFOwSePgp=s64","userId":"00474828135331575492"}},"outputId":"ecf65910-1b0e-41ca-cc0e-a8e9f805ecef"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["_arch\t\t\t       pytorch_model.bin\ttokenizer.json\n","config.json\t\t       special_tokens_map.json\tvocab.txt\n","pubmed_config_ex_base_s3.json  tokenizer_config.json\n"]}]},{"cell_type":"markdown","source":["Generate pre-training data. Please see https://github.com/google-research/bert for more details."],"metadata":{"id":"YlRuPnB5FIsH"}},{"cell_type":"code","source":["!ls exBERT/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b784AtBEJDdn","executionInfo":{"status":"ok","timestamp":1648471001712,"user_tz":-60,"elapsed":266,"user":{"displayName":"Lya Solis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0zQkkPA02m_TCbUFh15I5DgeImYkaFOwSePgp=s64","userId":"00474828135331575492"}},"outputId":"53154173-3058-42ae-85a8-9c42fd5fb1ef"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["convert_gpt2_checkpoint_to_pytorch.py\t     modeling_transfo_xl.py\n","convert_openai_checkpoint_to_pytorch.py      modeling_transfo_xl_utilities.py\n","convert_tf_checkpoint_to_pytorch.py\t     optimization_openai.py\n","convert_transfo_xl_checkpoint_to_pytorch.py  optimization.py\n","file_utils.py\t\t\t\t     __pycache__\n","__init__.py\t\t\t\t     tokenization_gpt2.py\n","__main__.py\t\t\t\t     tokenization_openai.py\n","modeling_gpt2.py\t\t\t     tokenization.py\n","modeling_openai.py\t\t\t     tokenization_transfo_xl.py\n","modeling.py\n"]}]},{"cell_type":"code","source":["# Import generic wrappers\n","from transformers import AutoModel, AutoTokenizer, AutoConfig, AutoModelForMaskedLM"],"metadata":{"id":"hCFSGr2qO5lM","executionInfo":{"status":"ok","timestamp":1648471075890,"user_tz":-60,"elapsed":6069,"user":{"displayName":"Lya Solis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0zQkkPA02m_TCbUFh15I5DgeImYkaFOwSePgp=s64","userId":"00474828135331575492"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["model_name = '/content/drive/MyDrive/GitHub/exBERT/PubMED_train_files/PubMed'\n","model = AutoModel.from_pretrained(model_name)\n","tokenizer = AutoTokenizer.from_pretrained(model_name)"],"metadata":{"id":"4Qcvgmz7Pq6m","executionInfo":{"status":"ok","timestamp":1648471133533,"user_tz":-60,"elapsed":6826,"user":{"displayName":"Lya Solis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0zQkkPA02m_TCbUFh15I5DgeImYkaFOwSePgp=s64","userId":"00474828135331575492"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["#Testing\n","from exBERT import BertTokenizer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uw537eC6ODNA","executionInfo":{"status":"ok","timestamp":1648471143909,"user_tz":-60,"elapsed":254,"user":{"displayName":"Lya Solis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0zQkkPA02m_TCbUFh15I5DgeImYkaFOwSePgp=s64","userId":"00474828135331575492"}},"outputId":"c0630861-a1bb-43d7-9975-92a21de53b09"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"]}]},{"cell_type":"markdown","source":["Generating Training Data"],"metadata":{"id":"RVQQ8G14Stt7"}},{"cell_type":"code","source":["#For this we need raw text"],"metadata":{"id":"FCd0n8PrZ8Dw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python /content/drive/MyDrive/GitHub/exBERT/data_preprocess.py -voc /content/drive/MyDrive/GitHub/exBERT/PubMED_train_files/PubMed/vocab.txt -ls 128 -dp /content/drive/MyDrive/GitHub/exBERT/data/paragraphs.txt -n_c 5 -rd 1 -sp /content/drive/MyDrive/GitHub/exBERT/data/ex_bert_train_data_from_raw.pkl"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BTQ9OD4BODKJ","executionInfo":{"status":"ok","timestamp":1648472260269,"user_tz":-60,"elapsed":26071,"user":{"displayName":"Lya Solis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0zQkkPA02m_TCbUFh15I5DgeImYkaFOwSePgp=s64","userId":"00474828135331575492"}},"outputId":"33a745dc-dac4-44ad-a489-c032447c1fb9"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n","processing data, thie might take some time\n","100% 5/5 [00:00<00:00, 85250.08it/s]\n","generating random sequence\n"]}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IhCevbGGODHz","executionInfo":{"status":"ok","timestamp":1648471189930,"user_tz":-60,"elapsed":240,"user":{"displayName":"Lya Solis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0zQkkPA02m_TCbUFh15I5DgeImYkaFOwSePgp=s64","userId":"00474828135331575492"}},"outputId":"4108ba9f-55c5-4c9f-de43-4abe6291ed6a"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Mar 28 12:39:53 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["device = 'cuda'\n","import torch, gc\n","import os\n","gc.collect()\n","torch.cuda.empty_cache()"],"metadata":{"id":"fq5uveypODFN","executionInfo":{"status":"ok","timestamp":1648472319371,"user_tz":-60,"elapsed":293,"user":{"displayName":"Lya Solis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0zQkkPA02m_TCbUFh15I5DgeImYkaFOwSePgp=s64","userId":"00474828135331575492"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["!python /content/drive/MyDrive/GitHub/exBERT/Pretraining.py -e 1 -b 4 -sp /content/drive/MyDrive/GitHub/exBERT/PubMED_train_files/PubMed_output -dv 0 -lr 1e-04 -str exBERT -config /content/drive/MyDrive/GitHub/exBERT/PubMED_train_files/PubMed/config.json /content/drive/MyDrive/GitHub/exBERT/PubMED_train_files/PubMed/pubmed_config_ex_base_s3.json -vocab /content/drive/MyDrive/GitHub/exBERT/PubMED_train_files/PubMed/vocab.txt -pm_p /content/drive/MyDrive/GitHub/exBERT/PubMED_train_files/PubMed/pytorch_model.bin -dp /content/drive/MyDrive/GitHub/exBERT/data/ex_bert_train_data_from_raw.pkl -ls 128 -p 1 -t_ex_only \"\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sshgHF2-ODCn","executionInfo":{"status":"ok","timestamp":1648472801666,"user_tz":-60,"elapsed":471602,"user":{"displayName":"Lya Solis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0zQkkPA02m_TCbUFh15I5DgeImYkaFOwSePgp=s64","userId":"00474828135331575492"}},"outputId":"1ad134f0-7af5-40f9-ff6a-257785077346"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n","epochs: 1\n","batchsize: 4\n","save_path: /content/drive/MyDrive/GitHub/exBERT/PubMED_train_files/PubMed_output\n","device: [0]\n","learning_rate: 0.0001\n","strategy: exBERT\n","config: ['/content/drive/MyDrive/GitHub/exBERT/PubMED_train_files/PubMed/config.json', '/content/drive/MyDrive/GitHub/exBERT/PubMED_train_files/PubMed/pubmed_config_ex_base_s3.json']\n","vocab: /content/drive/MyDrive/GitHub/exBERT/PubMED_train_files/PubMed/vocab.txt\n","pretrained_model_path: /content/drive/MyDrive/GitHub/exBERT/PubMED_train_files/PubMed/pytorch_model.bin\n","pretrained_model_path_tf: None\n","datat_path: /content/drive/MyDrive/GitHub/exBERT/data/ex_bert_train_data_from_raw.pkl\n","longest_sentence: 128\n","percentage: 1.0\n","sep: 1\n","warmup: -1\n","train_extension_only: False\n","training with GPU: [0]\n","Building PyTorch model from configuration: {\n","  \"_name_or_path\": \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.17.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","Building PyTorch model from configuration: {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 4655\n","}\n","\n","The following part of model is goinig to be trained:\n","bert.embeddings.word_embeddings.weight\n","bert.embeddings.position_embeddings.weight\n","bert.embeddings.token_type_embeddings.weight\n","bert.embeddings.word_embeddings_ADD.weight\n","bert.embeddings.LayerNorm.weight\n","bert.embeddings.LayerNorm.bias\n","bert.encoder.layer.0.attention.self.query.weight\n","bert.encoder.layer.0.attention.self.query.bias\n","bert.encoder.layer.0.attention.self.key.weight\n","bert.encoder.layer.0.attention.self.key.bias\n","bert.encoder.layer.0.attention.self.value.weight\n","bert.encoder.layer.0.attention.self.value.bias\n","bert.encoder.layer.0.attention.output.dense.weight\n","bert.encoder.layer.0.attention.output.dense.bias\n","bert.encoder.layer.0.attention.output.LayerNorm.weight\n","bert.encoder.layer.0.attention.output.LayerNorm.bias\n","bert.encoder.layer.0.intermediate.dense.weight\n","bert.encoder.layer.0.intermediate.dense.bias\n","bert.encoder.layer.0.output.dense.weight\n","bert.encoder.layer.0.output.dense.bias\n","bert.encoder.layer.0.output.LayerNorm.weight\n","bert.encoder.layer.0.output.LayerNorm.bias\n","bert.encoder.layer.0.attention_ADD.self.query.weight\n","bert.encoder.layer.0.attention_ADD.self.query.bias\n","bert.encoder.layer.0.attention_ADD.self.key.weight\n","bert.encoder.layer.0.attention_ADD.self.key.bias\n","bert.encoder.layer.0.attention_ADD.self.value.weight\n","bert.encoder.layer.0.attention_ADD.self.value.bias\n","bert.encoder.layer.0.attention_ADD.output.dense.weight\n","bert.encoder.layer.0.attention_ADD.output.dense.bias\n","bert.encoder.layer.0.attention_ADD.output.LayerNorm.weight\n","bert.encoder.layer.0.attention_ADD.output.LayerNorm.bias\n","bert.encoder.layer.0.intermediate_ADD.dense.weight\n","bert.encoder.layer.0.intermediate_ADD.dense.bias\n","bert.encoder.layer.0.output_ADD.dense.weight\n","bert.encoder.layer.0.output_ADD.dense.bias\n","bert.encoder.layer.0.output_ADD.LayerNorm.weight\n","bert.encoder.layer.0.output_ADD.LayerNorm.bias\n","bert.encoder.layer.0.gate_ADD.weight\n","bert.encoder.layer.0.gate_ADD.bias\n","bert.encoder.layer.1.attention.self.query.weight\n","bert.encoder.layer.1.attention.self.query.bias\n","bert.encoder.layer.1.attention.self.key.weight\n","bert.encoder.layer.1.attention.self.key.bias\n","bert.encoder.layer.1.attention.self.value.weight\n","bert.encoder.layer.1.attention.self.value.bias\n","bert.encoder.layer.1.attention.output.dense.weight\n","bert.encoder.layer.1.attention.output.dense.bias\n","bert.encoder.layer.1.attention.output.LayerNorm.weight\n","bert.encoder.layer.1.attention.output.LayerNorm.bias\n","bert.encoder.layer.1.intermediate.dense.weight\n","bert.encoder.layer.1.intermediate.dense.bias\n","bert.encoder.layer.1.output.dense.weight\n","bert.encoder.layer.1.output.dense.bias\n","bert.encoder.layer.1.output.LayerNorm.weight\n","bert.encoder.layer.1.output.LayerNorm.bias\n","bert.encoder.layer.1.attention_ADD.self.query.weight\n","bert.encoder.layer.1.attention_ADD.self.query.bias\n","bert.encoder.layer.1.attention_ADD.self.key.weight\n","bert.encoder.layer.1.attention_ADD.self.key.bias\n","bert.encoder.layer.1.attention_ADD.self.value.weight\n","bert.encoder.layer.1.attention_ADD.self.value.bias\n","bert.encoder.layer.1.attention_ADD.output.dense.weight\n","bert.encoder.layer.1.attention_ADD.output.dense.bias\n","bert.encoder.layer.1.attention_ADD.output.LayerNorm.weight\n","bert.encoder.layer.1.attention_ADD.output.LayerNorm.bias\n","bert.encoder.layer.1.intermediate_ADD.dense.weight\n","bert.encoder.layer.1.intermediate_ADD.dense.bias\n","bert.encoder.layer.1.output_ADD.dense.weight\n","bert.encoder.layer.1.output_ADD.dense.bias\n","bert.encoder.layer.1.output_ADD.LayerNorm.weight\n","bert.encoder.layer.1.output_ADD.LayerNorm.bias\n","bert.encoder.layer.1.gate_ADD.weight\n","bert.encoder.layer.1.gate_ADD.bias\n","bert.encoder.layer.2.attention.self.query.weight\n","bert.encoder.layer.2.attention.self.query.bias\n","bert.encoder.layer.2.attention.self.key.weight\n","bert.encoder.layer.2.attention.self.key.bias\n","bert.encoder.layer.2.attention.self.value.weight\n","bert.encoder.layer.2.attention.self.value.bias\n","bert.encoder.layer.2.attention.output.dense.weight\n","bert.encoder.layer.2.attention.output.dense.bias\n","bert.encoder.layer.2.attention.output.LayerNorm.weight\n","bert.encoder.layer.2.attention.output.LayerNorm.bias\n","bert.encoder.layer.2.intermediate.dense.weight\n","bert.encoder.layer.2.intermediate.dense.bias\n","bert.encoder.layer.2.output.dense.weight\n","bert.encoder.layer.2.output.dense.bias\n","bert.encoder.layer.2.output.LayerNorm.weight\n","bert.encoder.layer.2.output.LayerNorm.bias\n","bert.encoder.layer.2.attention_ADD.self.query.weight\n","bert.encoder.layer.2.attention_ADD.self.query.bias\n","bert.encoder.layer.2.attention_ADD.self.key.weight\n","bert.encoder.layer.2.attention_ADD.self.key.bias\n","bert.encoder.layer.2.attention_ADD.self.value.weight\n","bert.encoder.layer.2.attention_ADD.self.value.bias\n","bert.encoder.layer.2.attention_ADD.output.dense.weight\n","bert.encoder.layer.2.attention_ADD.output.dense.bias\n","bert.encoder.layer.2.attention_ADD.output.LayerNorm.weight\n","bert.encoder.layer.2.attention_ADD.output.LayerNorm.bias\n","bert.encoder.layer.2.intermediate_ADD.dense.weight\n","bert.encoder.layer.2.intermediate_ADD.dense.bias\n","bert.encoder.layer.2.output_ADD.dense.weight\n","bert.encoder.layer.2.output_ADD.dense.bias\n","bert.encoder.layer.2.output_ADD.LayerNorm.weight\n","bert.encoder.layer.2.output_ADD.LayerNorm.bias\n","bert.encoder.layer.2.gate_ADD.weight\n","bert.encoder.layer.2.gate_ADD.bias\n","bert.encoder.layer.3.attention.self.query.weight\n","bert.encoder.layer.3.attention.self.query.bias\n","bert.encoder.layer.3.attention.self.key.weight\n","bert.encoder.layer.3.attention.self.key.bias\n","bert.encoder.layer.3.attention.self.value.weight\n","bert.encoder.layer.3.attention.self.value.bias\n","bert.encoder.layer.3.attention.output.dense.weight\n","bert.encoder.layer.3.attention.output.dense.bias\n","bert.encoder.layer.3.attention.output.LayerNorm.weight\n","bert.encoder.layer.3.attention.output.LayerNorm.bias\n","bert.encoder.layer.3.intermediate.dense.weight\n","bert.encoder.layer.3.intermediate.dense.bias\n","bert.encoder.layer.3.output.dense.weight\n","bert.encoder.layer.3.output.dense.bias\n","bert.encoder.layer.3.output.LayerNorm.weight\n","bert.encoder.layer.3.output.LayerNorm.bias\n","bert.encoder.layer.3.attention_ADD.self.query.weight\n","bert.encoder.layer.3.attention_ADD.self.query.bias\n","bert.encoder.layer.3.attention_ADD.self.key.weight\n","bert.encoder.layer.3.attention_ADD.self.key.bias\n","bert.encoder.layer.3.attention_ADD.self.value.weight\n","bert.encoder.layer.3.attention_ADD.self.value.bias\n","bert.encoder.layer.3.attention_ADD.output.dense.weight\n","bert.encoder.layer.3.attention_ADD.output.dense.bias\n","bert.encoder.layer.3.attention_ADD.output.LayerNorm.weight\n","bert.encoder.layer.3.attention_ADD.output.LayerNorm.bias\n","bert.encoder.layer.3.intermediate_ADD.dense.weight\n","bert.encoder.layer.3.intermediate_ADD.dense.bias\n","bert.encoder.layer.3.output_ADD.dense.weight\n","bert.encoder.layer.3.output_ADD.dense.bias\n","bert.encoder.layer.3.output_ADD.LayerNorm.weight\n","bert.encoder.layer.3.output_ADD.LayerNorm.bias\n","bert.encoder.layer.3.gate_ADD.weight\n","bert.encoder.layer.3.gate_ADD.bias\n","bert.encoder.layer.4.attention.self.query.weight\n","bert.encoder.layer.4.attention.self.query.bias\n","bert.encoder.layer.4.attention.self.key.weight\n","bert.encoder.layer.4.attention.self.key.bias\n","bert.encoder.layer.4.attention.self.value.weight\n","bert.encoder.layer.4.attention.self.value.bias\n","bert.encoder.layer.4.attention.output.dense.weight\n","bert.encoder.layer.4.attention.output.dense.bias\n","bert.encoder.layer.4.attention.output.LayerNorm.weight\n","bert.encoder.layer.4.attention.output.LayerNorm.bias\n","bert.encoder.layer.4.intermediate.dense.weight\n","bert.encoder.layer.4.intermediate.dense.bias\n","bert.encoder.layer.4.output.dense.weight\n","bert.encoder.layer.4.output.dense.bias\n","bert.encoder.layer.4.output.LayerNorm.weight\n","bert.encoder.layer.4.output.LayerNorm.bias\n","bert.encoder.layer.4.attention_ADD.self.query.weight\n","bert.encoder.layer.4.attention_ADD.self.query.bias\n","bert.encoder.layer.4.attention_ADD.self.key.weight\n","bert.encoder.layer.4.attention_ADD.self.key.bias\n","bert.encoder.layer.4.attention_ADD.self.value.weight\n","bert.encoder.layer.4.attention_ADD.self.value.bias\n","bert.encoder.layer.4.attention_ADD.output.dense.weight\n","bert.encoder.layer.4.attention_ADD.output.dense.bias\n","bert.encoder.layer.4.attention_ADD.output.LayerNorm.weight\n","bert.encoder.layer.4.attention_ADD.output.LayerNorm.bias\n","bert.encoder.layer.4.intermediate_ADD.dense.weight\n","bert.encoder.layer.4.intermediate_ADD.dense.bias\n","bert.encoder.layer.4.output_ADD.dense.weight\n","bert.encoder.layer.4.output_ADD.dense.bias\n","bert.encoder.layer.4.output_ADD.LayerNorm.weight\n","bert.encoder.layer.4.output_ADD.LayerNorm.bias\n","bert.encoder.layer.4.gate_ADD.weight\n","bert.encoder.layer.4.gate_ADD.bias\n","bert.encoder.layer.5.attention.self.query.weight\n","bert.encoder.layer.5.attention.self.query.bias\n","bert.encoder.layer.5.attention.self.key.weight\n","bert.encoder.layer.5.attention.self.key.bias\n","bert.encoder.layer.5.attention.self.value.weight\n","bert.encoder.layer.5.attention.self.value.bias\n","bert.encoder.layer.5.attention.output.dense.weight\n","bert.encoder.layer.5.attention.output.dense.bias\n","bert.encoder.layer.5.attention.output.LayerNorm.weight\n","bert.encoder.layer.5.attention.output.LayerNorm.bias\n","bert.encoder.layer.5.intermediate.dense.weight\n","bert.encoder.layer.5.intermediate.dense.bias\n","bert.encoder.layer.5.output.dense.weight\n","bert.encoder.layer.5.output.dense.bias\n","bert.encoder.layer.5.output.LayerNorm.weight\n","bert.encoder.layer.5.output.LayerNorm.bias\n","bert.encoder.layer.5.attention_ADD.self.query.weight\n","bert.encoder.layer.5.attention_ADD.self.query.bias\n","bert.encoder.layer.5.attention_ADD.self.key.weight\n","bert.encoder.layer.5.attention_ADD.self.key.bias\n","bert.encoder.layer.5.attention_ADD.self.value.weight\n","bert.encoder.layer.5.attention_ADD.self.value.bias\n","bert.encoder.layer.5.attention_ADD.output.dense.weight\n","bert.encoder.layer.5.attention_ADD.output.dense.bias\n","bert.encoder.layer.5.attention_ADD.output.LayerNorm.weight\n","bert.encoder.layer.5.attention_ADD.output.LayerNorm.bias\n","bert.encoder.layer.5.intermediate_ADD.dense.weight\n","bert.encoder.layer.5.intermediate_ADD.dense.bias\n","bert.encoder.layer.5.output_ADD.dense.weight\n","bert.encoder.layer.5.output_ADD.dense.bias\n","bert.encoder.layer.5.output_ADD.LayerNorm.weight\n","bert.encoder.layer.5.output_ADD.LayerNorm.bias\n","bert.encoder.layer.5.gate_ADD.weight\n","bert.encoder.layer.5.gate_ADD.bias\n","bert.encoder.layer.6.attention.self.query.weight\n","bert.encoder.layer.6.attention.self.query.bias\n","bert.encoder.layer.6.attention.self.key.weight\n","bert.encoder.layer.6.attention.self.key.bias\n","bert.encoder.layer.6.attention.self.value.weight\n","bert.encoder.layer.6.attention.self.value.bias\n","bert.encoder.layer.6.attention.output.dense.weight\n","bert.encoder.layer.6.attention.output.dense.bias\n","bert.encoder.layer.6.attention.output.LayerNorm.weight\n","bert.encoder.layer.6.attention.output.LayerNorm.bias\n","bert.encoder.layer.6.intermediate.dense.weight\n","bert.encoder.layer.6.intermediate.dense.bias\n","bert.encoder.layer.6.output.dense.weight\n","bert.encoder.layer.6.output.dense.bias\n","bert.encoder.layer.6.output.LayerNorm.weight\n","bert.encoder.layer.6.output.LayerNorm.bias\n","bert.encoder.layer.6.attention_ADD.self.query.weight\n","bert.encoder.layer.6.attention_ADD.self.query.bias\n","bert.encoder.layer.6.attention_ADD.self.key.weight\n","bert.encoder.layer.6.attention_ADD.self.key.bias\n","bert.encoder.layer.6.attention_ADD.self.value.weight\n","bert.encoder.layer.6.attention_ADD.self.value.bias\n","bert.encoder.layer.6.attention_ADD.output.dense.weight\n","bert.encoder.layer.6.attention_ADD.output.dense.bias\n","bert.encoder.layer.6.attention_ADD.output.LayerNorm.weight\n","bert.encoder.layer.6.attention_ADD.output.LayerNorm.bias\n","bert.encoder.layer.6.intermediate_ADD.dense.weight\n","bert.encoder.layer.6.intermediate_ADD.dense.bias\n","bert.encoder.layer.6.output_ADD.dense.weight\n","bert.encoder.layer.6.output_ADD.dense.bias\n","bert.encoder.layer.6.output_ADD.LayerNorm.weight\n","bert.encoder.layer.6.output_ADD.LayerNorm.bias\n","bert.encoder.layer.6.gate_ADD.weight\n","bert.encoder.layer.6.gate_ADD.bias\n","bert.encoder.layer.7.attention.self.query.weight\n","bert.encoder.layer.7.attention.self.query.bias\n","bert.encoder.layer.7.attention.self.key.weight\n","bert.encoder.layer.7.attention.self.key.bias\n","bert.encoder.layer.7.attention.self.value.weight\n","bert.encoder.layer.7.attention.self.value.bias\n","bert.encoder.layer.7.attention.output.dense.weight\n","bert.encoder.layer.7.attention.output.dense.bias\n","bert.encoder.layer.7.attention.output.LayerNorm.weight\n","bert.encoder.layer.7.attention.output.LayerNorm.bias\n","bert.encoder.layer.7.intermediate.dense.weight\n","bert.encoder.layer.7.intermediate.dense.bias\n","bert.encoder.layer.7.output.dense.weight\n","bert.encoder.layer.7.output.dense.bias\n","bert.encoder.layer.7.output.LayerNorm.weight\n","bert.encoder.layer.7.output.LayerNorm.bias\n","bert.encoder.layer.7.attention_ADD.self.query.weight\n","bert.encoder.layer.7.attention_ADD.self.query.bias\n","bert.encoder.layer.7.attention_ADD.self.key.weight\n","bert.encoder.layer.7.attention_ADD.self.key.bias\n","bert.encoder.layer.7.attention_ADD.self.value.weight\n","bert.encoder.layer.7.attention_ADD.self.value.bias\n","bert.encoder.layer.7.attention_ADD.output.dense.weight\n","bert.encoder.layer.7.attention_ADD.output.dense.bias\n","bert.encoder.layer.7.attention_ADD.output.LayerNorm.weight\n","bert.encoder.layer.7.attention_ADD.output.LayerNorm.bias\n","bert.encoder.layer.7.intermediate_ADD.dense.weight\n","bert.encoder.layer.7.intermediate_ADD.dense.bias\n","bert.encoder.layer.7.output_ADD.dense.weight\n","bert.encoder.layer.7.output_ADD.dense.bias\n","bert.encoder.layer.7.output_ADD.LayerNorm.weight\n","bert.encoder.layer.7.output_ADD.LayerNorm.bias\n","bert.encoder.layer.7.gate_ADD.weight\n","bert.encoder.layer.7.gate_ADD.bias\n","bert.encoder.layer.8.attention.self.query.weight\n","bert.encoder.layer.8.attention.self.query.bias\n","bert.encoder.layer.8.attention.self.key.weight\n","bert.encoder.layer.8.attention.self.key.bias\n","bert.encoder.layer.8.attention.self.value.weight\n","bert.encoder.layer.8.attention.self.value.bias\n","bert.encoder.layer.8.attention.output.dense.weight\n","bert.encoder.layer.8.attention.output.dense.bias\n","bert.encoder.layer.8.attention.output.LayerNorm.weight\n","bert.encoder.layer.8.attention.output.LayerNorm.bias\n","bert.encoder.layer.8.intermediate.dense.weight\n","bert.encoder.layer.8.intermediate.dense.bias\n","bert.encoder.layer.8.output.dense.weight\n","bert.encoder.layer.8.output.dense.bias\n","bert.encoder.layer.8.output.LayerNorm.weight\n","bert.encoder.layer.8.output.LayerNorm.bias\n","bert.encoder.layer.8.attention_ADD.self.query.weight\n","bert.encoder.layer.8.attention_ADD.self.query.bias\n","bert.encoder.layer.8.attention_ADD.self.key.weight\n","bert.encoder.layer.8.attention_ADD.self.key.bias\n","bert.encoder.layer.8.attention_ADD.self.value.weight\n","bert.encoder.layer.8.attention_ADD.self.value.bias\n","bert.encoder.layer.8.attention_ADD.output.dense.weight\n","bert.encoder.layer.8.attention_ADD.output.dense.bias\n","bert.encoder.layer.8.attention_ADD.output.LayerNorm.weight\n","bert.encoder.layer.8.attention_ADD.output.LayerNorm.bias\n","bert.encoder.layer.8.intermediate_ADD.dense.weight\n","bert.encoder.layer.8.intermediate_ADD.dense.bias\n","bert.encoder.layer.8.output_ADD.dense.weight\n","bert.encoder.layer.8.output_ADD.dense.bias\n","bert.encoder.layer.8.output_ADD.LayerNorm.weight\n","bert.encoder.layer.8.output_ADD.LayerNorm.bias\n","bert.encoder.layer.8.gate_ADD.weight\n","bert.encoder.layer.8.gate_ADD.bias\n","bert.encoder.layer.9.attention.self.query.weight\n","bert.encoder.layer.9.attention.self.query.bias\n","bert.encoder.layer.9.attention.self.key.weight\n","bert.encoder.layer.9.attention.self.key.bias\n","bert.encoder.layer.9.attention.self.value.weight\n","bert.encoder.layer.9.attention.self.value.bias\n","bert.encoder.layer.9.attention.output.dense.weight\n","bert.encoder.layer.9.attention.output.dense.bias\n","bert.encoder.layer.9.attention.output.LayerNorm.weight\n","bert.encoder.layer.9.attention.output.LayerNorm.bias\n","bert.encoder.layer.9.intermediate.dense.weight\n","bert.encoder.layer.9.intermediate.dense.bias\n","bert.encoder.layer.9.output.dense.weight\n","bert.encoder.layer.9.output.dense.bias\n","bert.encoder.layer.9.output.LayerNorm.weight\n","bert.encoder.layer.9.output.LayerNorm.bias\n","bert.encoder.layer.9.attention_ADD.self.query.weight\n","bert.encoder.layer.9.attention_ADD.self.query.bias\n","bert.encoder.layer.9.attention_ADD.self.key.weight\n","bert.encoder.layer.9.attention_ADD.self.key.bias\n","bert.encoder.layer.9.attention_ADD.self.value.weight\n","bert.encoder.layer.9.attention_ADD.self.value.bias\n","bert.encoder.layer.9.attention_ADD.output.dense.weight\n","bert.encoder.layer.9.attention_ADD.output.dense.bias\n","bert.encoder.layer.9.attention_ADD.output.LayerNorm.weight\n","bert.encoder.layer.9.attention_ADD.output.LayerNorm.bias\n","bert.encoder.layer.9.intermediate_ADD.dense.weight\n","bert.encoder.layer.9.intermediate_ADD.dense.bias\n","bert.encoder.layer.9.output_ADD.dense.weight\n","bert.encoder.layer.9.output_ADD.dense.bias\n","bert.encoder.layer.9.output_ADD.LayerNorm.weight\n","bert.encoder.layer.9.output_ADD.LayerNorm.bias\n","bert.encoder.layer.9.gate_ADD.weight\n","bert.encoder.layer.9.gate_ADD.bias\n","bert.encoder.layer.10.attention.self.query.weight\n","bert.encoder.layer.10.attention.self.query.bias\n","bert.encoder.layer.10.attention.self.key.weight\n","bert.encoder.layer.10.attention.self.key.bias\n","bert.encoder.layer.10.attention.self.value.weight\n","bert.encoder.layer.10.attention.self.value.bias\n","bert.encoder.layer.10.attention.output.dense.weight\n","bert.encoder.layer.10.attention.output.dense.bias\n","bert.encoder.layer.10.attention.output.LayerNorm.weight\n","bert.encoder.layer.10.attention.output.LayerNorm.bias\n","bert.encoder.layer.10.intermediate.dense.weight\n","bert.encoder.layer.10.intermediate.dense.bias\n","bert.encoder.layer.10.output.dense.weight\n","bert.encoder.layer.10.output.dense.bias\n","bert.encoder.layer.10.output.LayerNorm.weight\n","bert.encoder.layer.10.output.LayerNorm.bias\n","bert.encoder.layer.10.attention_ADD.self.query.weight\n","bert.encoder.layer.10.attention_ADD.self.query.bias\n","bert.encoder.layer.10.attention_ADD.self.key.weight\n","bert.encoder.layer.10.attention_ADD.self.key.bias\n","bert.encoder.layer.10.attention_ADD.self.value.weight\n","bert.encoder.layer.10.attention_ADD.self.value.bias\n","bert.encoder.layer.10.attention_ADD.output.dense.weight\n","bert.encoder.layer.10.attention_ADD.output.dense.bias\n","bert.encoder.layer.10.attention_ADD.output.LayerNorm.weight\n","bert.encoder.layer.10.attention_ADD.output.LayerNorm.bias\n","bert.encoder.layer.10.intermediate_ADD.dense.weight\n","bert.encoder.layer.10.intermediate_ADD.dense.bias\n","bert.encoder.layer.10.output_ADD.dense.weight\n","bert.encoder.layer.10.output_ADD.dense.bias\n","bert.encoder.layer.10.output_ADD.LayerNorm.weight\n","bert.encoder.layer.10.output_ADD.LayerNorm.bias\n","bert.encoder.layer.10.gate_ADD.weight\n","bert.encoder.layer.10.gate_ADD.bias\n","bert.encoder.layer.11.attention.self.query.weight\n","bert.encoder.layer.11.attention.self.query.bias\n","bert.encoder.layer.11.attention.self.key.weight\n","bert.encoder.layer.11.attention.self.key.bias\n","bert.encoder.layer.11.attention.self.value.weight\n","bert.encoder.layer.11.attention.self.value.bias\n","bert.encoder.layer.11.attention.output.dense.weight\n","bert.encoder.layer.11.attention.output.dense.bias\n","bert.encoder.layer.11.attention.output.LayerNorm.weight\n","bert.encoder.layer.11.attention.output.LayerNorm.bias\n","bert.encoder.layer.11.intermediate.dense.weight\n","bert.encoder.layer.11.intermediate.dense.bias\n","bert.encoder.layer.11.output.dense.weight\n","bert.encoder.layer.11.output.dense.bias\n","bert.encoder.layer.11.output.LayerNorm.weight\n","bert.encoder.layer.11.output.LayerNorm.bias\n","bert.encoder.layer.11.attention_ADD.self.query.weight\n","bert.encoder.layer.11.attention_ADD.self.query.bias\n","bert.encoder.layer.11.attention_ADD.self.key.weight\n","bert.encoder.layer.11.attention_ADD.self.key.bias\n","bert.encoder.layer.11.attention_ADD.self.value.weight\n","bert.encoder.layer.11.attention_ADD.self.value.bias\n","bert.encoder.layer.11.attention_ADD.output.dense.weight\n","bert.encoder.layer.11.attention_ADD.output.dense.bias\n","bert.encoder.layer.11.attention_ADD.output.LayerNorm.weight\n","bert.encoder.layer.11.attention_ADD.output.LayerNorm.bias\n","bert.encoder.layer.11.intermediate_ADD.dense.weight\n","bert.encoder.layer.11.intermediate_ADD.dense.bias\n","bert.encoder.layer.11.output_ADD.dense.weight\n","bert.encoder.layer.11.output_ADD.dense.bias\n","bert.encoder.layer.11.output_ADD.LayerNorm.weight\n","bert.encoder.layer.11.output_ADD.LayerNorm.bias\n","bert.encoder.layer.11.gate_ADD.weight\n","bert.encoder.layer.11.gate_ADD.bias\n","bert.pooler.dense.weight\n","bert.pooler.dense.bias\n","cls.predictions.bias\n","cls.predictions.bias_ADD\n","cls.predictions.transform.dense.weight\n","cls.predictions.transform.dense.bias\n","cls.predictions.transform.LayerNorm.weight\n","cls.predictions.transform.LayerNorm.bias\n","cls.seq_relationship.weight\n","cls.seq_relationship.bias\n","loading data: /content/drive/MyDrive/GitHub/exBERT/data/ex_bert_train_data_from_raw.pkl\n","shuffle data\n","done data preparation\n","data number: 6456\n","loading data: /content/drive/MyDrive/GitHub/exBERT/data/ex_bert_train_data_from_raw.pkl\n","shuffle data\n","/content/drive/MyDrive/GitHub/exBERT/exBERT/optimization.py:133: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)\n","  next_m.mul_(beta1).add_(1 - beta1, grad)\n","Train Epoch: 0 [32/6456 (0%)]\ttrain_Loss: 2.93921 \tval_Loss: 0.00000 time: 2.4729 \t lr:0.000099\n","Train Epoch: 0 [64/6456 (1%)]\ttrain_Loss: 2.29339 \tval_Loss: 0.00000 time: 4.9179 \t lr:0.000099\n","Train Epoch: 0 [96/6456 (1%)]\ttrain_Loss: 2.12212 \tval_Loss: 0.00000 time: 7.0497 \t lr:0.000098\n","Train Epoch: 0 [128/6456 (2%)]\ttrain_Loss: 1.99239 \tval_Loss: 0.00000 time: 9.1902 \t lr:0.000098\n","Train Epoch: 0 [160/6456 (2%)]\ttrain_Loss: 2.03035 \tval_Loss: 0.00000 time: 11.3140 \t lr:0.000097\n","Train Epoch: 0 [192/6456 (3%)]\ttrain_Loss: 2.04865 \tval_Loss: 0.00000 time: 13.4439 \t lr:0.000097\n","Train Epoch: 0 [224/6456 (3%)]\ttrain_Loss: 1.89051 \tval_Loss: 0.00000 time: 15.5569 \t lr:0.000096\n","Train Epoch: 0 [256/6456 (4%)]\ttrain_Loss: 1.94137 \tval_Loss: 0.00000 time: 17.7141 \t lr:0.000096\n","Train Epoch: 0 [288/6456 (4%)]\ttrain_Loss: 1.98804 \tval_Loss: 0.00000 time: 19.8518 \t lr:0.000095\n","Train Epoch: 0 [320/6456 (5%)]\ttrain_Loss: 1.98459 \tval_Loss: 0.00000 time: 21.9876 \t lr:0.000095\n","Train Epoch: 0 [352/6456 (5%)]\ttrain_Loss: 1.89310 \tval_Loss: 0.00000 time: 24.1113 \t lr:0.000094\n","Train Epoch: 0 [384/6456 (6%)]\ttrain_Loss: 1.96680 \tval_Loss: 0.00000 time: 26.2449 \t lr:0.000094\n","Train Epoch: 0 [416/6456 (6%)]\ttrain_Loss: 1.84768 \tval_Loss: 0.00000 time: 28.3766 \t lr:0.000093\n","Train Epoch: 0 [448/6456 (7%)]\ttrain_Loss: 1.92016 \tval_Loss: 0.00000 time: 30.5002 \t lr:0.000093\n","Train Epoch: 0 [480/6456 (7%)]\ttrain_Loss: 1.88134 \tval_Loss: 0.00000 time: 32.6236 \t lr:0.000093\n","Train Epoch: 0 [512/6456 (8%)]\ttrain_Loss: 1.93305 \tval_Loss: 0.00000 time: 34.7494 \t lr:0.000092\n","Train Epoch: 0 [544/6456 (8%)]\ttrain_Loss: 1.84587 \tval_Loss: 0.00000 time: 36.8674 \t lr:0.000092\n","Train Epoch: 0 [576/6456 (9%)]\ttrain_Loss: 1.86416 \tval_Loss: 0.00000 time: 38.9946 \t lr:0.000091\n","Train Epoch: 0 [608/6456 (9%)]\ttrain_Loss: 1.93599 \tval_Loss: 0.00000 time: 41.1161 \t lr:0.000091\n","Train Epoch: 0 [640/6456 (10%)]\ttrain_Loss: 1.85422 \tval_Loss: 0.00000 time: 43.2411 \t lr:0.000090\n","Train Epoch: 0 [672/6456 (10%)]\ttrain_Loss: 1.87630 \tval_Loss: 0.00000 time: 45.3688 \t lr:0.000090\n","Train Epoch: 0 [704/6456 (11%)]\ttrain_Loss: 1.91878 \tval_Loss: 0.00000 time: 47.4960 \t lr:0.000089\n","Train Epoch: 0 [736/6456 (11%)]\ttrain_Loss: 1.89594 \tval_Loss: 0.00000 time: 49.6300 \t lr:0.000089\n","Train Epoch: 0 [768/6456 (12%)]\ttrain_Loss: 1.85047 \tval_Loss: 0.00000 time: 51.7640 \t lr:0.000088\n","Train Epoch: 0 [800/6456 (12%)]\ttrain_Loss: 1.84434 \tval_Loss: 0.00000 time: 53.8950 \t lr:0.000088\n","Train Epoch: 0 [832/6456 (13%)]\ttrain_Loss: 1.86344 \tval_Loss: 0.00000 time: 56.0232 \t lr:0.000087\n","Train Epoch: 0 [864/6456 (13%)]\ttrain_Loss: 1.89441 \tval_Loss: 0.00000 time: 58.1691 \t lr:0.000087\n","Train Epoch: 0 [896/6456 (14%)]\ttrain_Loss: 1.95620 \tval_Loss: 0.00000 time: 60.3085 \t lr:0.000086\n","Train Epoch: 0 [928/6456 (14%)]\ttrain_Loss: 1.88923 \tval_Loss: 0.00000 time: 62.4265 \t lr:0.000086\n","Train Epoch: 0 [960/6456 (15%)]\ttrain_Loss: 1.85348 \tval_Loss: 0.00000 time: 64.5598 \t lr:0.000085\n","Train Epoch: 0 [992/6456 (15%)]\ttrain_Loss: 1.91881 \tval_Loss: 0.00000 time: 66.6893 \t lr:0.000085\n","Train Epoch: 0 [1024/6456 (16%)]\ttrain_Loss: 1.83416 \tval_Loss: 0.00000 time: 68.8255 \t lr:0.000084\n","Train Epoch: 0 [1056/6456 (16%)]\ttrain_Loss: 1.83681 \tval_Loss: 0.00000 time: 70.9497 \t lr:0.000084\n","Train Epoch: 0 [1088/6456 (17%)]\ttrain_Loss: 1.81789 \tval_Loss: 0.00000 time: 73.0942 \t lr:0.000083\n","Train Epoch: 0 [1120/6456 (17%)]\ttrain_Loss: 1.93293 \tval_Loss: 0.00000 time: 75.2373 \t lr:0.000083\n","Train Epoch: 0 [1152/6456 (18%)]\ttrain_Loss: 1.81201 \tval_Loss: 0.00000 time: 77.3765 \t lr:0.000082\n","Train Epoch: 0 [1184/6456 (18%)]\ttrain_Loss: 1.84989 \tval_Loss: 0.00000 time: 79.5083 \t lr:0.000082\n","Train Epoch: 0 [1216/6456 (19%)]\ttrain_Loss: 1.80088 \tval_Loss: 0.00000 time: 81.6447 \t lr:0.000081\n","Train Epoch: 0 [1248/6456 (19%)]\ttrain_Loss: 1.81076 \tval_Loss: 0.00000 time: 83.7811 \t lr:0.000081\n","Train Epoch: 0 [1280/6456 (20%)]\ttrain_Loss: 1.93434 \tval_Loss: 0.00000 time: 85.9106 \t lr:0.000080\n","Train Epoch: 0 [1312/6456 (20%)]\ttrain_Loss: 1.85921 \tval_Loss: 0.00000 time: 88.0493 \t lr:0.000080\n","Train Epoch: 0 [1344/6456 (21%)]\ttrain_Loss: 1.84851 \tval_Loss: 0.00000 time: 90.1781 \t lr:0.000079\n","Train Epoch: 0 [1376/6456 (21%)]\ttrain_Loss: 1.86930 \tval_Loss: 0.00000 time: 92.3060 \t lr:0.000079\n","Train Epoch: 0 [1408/6456 (22%)]\ttrain_Loss: 1.81751 \tval_Loss: 0.00000 time: 94.4325 \t lr:0.000078\n","Train Epoch: 0 [1440/6456 (22%)]\ttrain_Loss: 1.81653 \tval_Loss: 0.00000 time: 96.5700 \t lr:0.000078\n","Train Epoch: 0 [1472/6456 (23%)]\ttrain_Loss: 1.73377 \tval_Loss: 0.00000 time: 98.6922 \t lr:0.000077\n","Train Epoch: 0 [1504/6456 (23%)]\ttrain_Loss: 1.83134 \tval_Loss: 0.00000 time: 100.8301 \t lr:0.000077\n","Train Epoch: 0 [1536/6456 (24%)]\ttrain_Loss: 1.77043 \tval_Loss: 0.00000 time: 102.9506 \t lr:0.000076\n","Train Epoch: 0 [1568/6456 (24%)]\ttrain_Loss: 1.89566 \tval_Loss: 0.00000 time: 105.0960 \t lr:0.000076\n","Train Epoch: 0 [1600/6456 (25%)]\ttrain_Loss: 1.82043 \tval_Loss: 0.00000 time: 107.2226 \t lr:0.000075\n","Train Epoch: 0 [1632/6456 (25%)]\ttrain_Loss: 1.86180 \tval_Loss: 0.00000 time: 109.3587 \t lr:0.000075\n","Train Epoch: 0 [1664/6456 (26%)]\ttrain_Loss: 1.85299 \tval_Loss: 0.00000 time: 111.4868 \t lr:0.000074\n","Train Epoch: 0 [1696/6456 (26%)]\ttrain_Loss: 1.85914 \tval_Loss: 0.00000 time: 113.6169 \t lr:0.000074\n","Train Epoch: 0 [1728/6456 (27%)]\ttrain_Loss: 1.88015 \tval_Loss: 0.00000 time: 115.7421 \t lr:0.000073\n","Train Epoch: 0 [1760/6456 (27%)]\ttrain_Loss: 1.83725 \tval_Loss: 0.00000 time: 117.8726 \t lr:0.000073\n","Train Epoch: 0 [1792/6456 (28%)]\ttrain_Loss: 1.80434 \tval_Loss: 0.00000 time: 120.0214 \t lr:0.000072\n","Train Epoch: 0 [1824/6456 (28%)]\ttrain_Loss: 1.83406 \tval_Loss: 0.00000 time: 122.1419 \t lr:0.000072\n","Train Epoch: 0 [1856/6456 (29%)]\ttrain_Loss: 1.84020 \tval_Loss: 0.00000 time: 124.2651 \t lr:0.000071\n","Train Epoch: 0 [1888/6456 (29%)]\ttrain_Loss: 1.83957 \tval_Loss: 0.00000 time: 126.4009 \t lr:0.000071\n","Train Epoch: 0 [1920/6456 (30%)]\ttrain_Loss: 1.88846 \tval_Loss: 0.00000 time: 128.5334 \t lr:0.000070\n","Train Epoch: 0 [1952/6456 (30%)]\ttrain_Loss: 1.82226 \tval_Loss: 0.00000 time: 130.6601 \t lr:0.000070\n","Train Epoch: 0 [1984/6456 (31%)]\ttrain_Loss: 1.82597 \tval_Loss: 0.00000 time: 132.7899 \t lr:0.000069\n","Train Epoch: 0 [2016/6456 (31%)]\ttrain_Loss: 1.79688 \tval_Loss: 0.00000 time: 134.9135 \t lr:0.000069\n","Train Epoch: 0 [2048/6456 (32%)]\ttrain_Loss: 1.80205 \tval_Loss: 0.00000 time: 137.0417 \t lr:0.000068\n","Train Epoch: 0 [2080/6456 (32%)]\ttrain_Loss: 1.77420 \tval_Loss: 0.00000 time: 139.1694 \t lr:0.000068\n","Train Epoch: 0 [2112/6456 (33%)]\ttrain_Loss: 1.82231 \tval_Loss: 0.00000 time: 141.3051 \t lr:0.000067\n","Train Epoch: 0 [2144/6456 (33%)]\ttrain_Loss: 1.82279 \tval_Loss: 0.00000 time: 143.4581 \t lr:0.000067\n","Train Epoch: 0 [2176/6456 (34%)]\ttrain_Loss: 1.79947 \tval_Loss: 0.00000 time: 145.5836 \t lr:0.000066\n","Train Epoch: 0 [2208/6456 (34%)]\ttrain_Loss: 1.79795 \tval_Loss: 0.00000 time: 147.7089 \t lr:0.000066\n","Train Epoch: 0 [2240/6456 (35%)]\ttrain_Loss: 1.90581 \tval_Loss: 0.00000 time: 149.8427 \t lr:0.000065\n","Train Epoch: 0 [2272/6456 (35%)]\ttrain_Loss: 1.89395 \tval_Loss: 0.00000 time: 151.9869 \t lr:0.000065\n","Train Epoch: 0 [2304/6456 (36%)]\ttrain_Loss: 1.80734 \tval_Loss: 0.00000 time: 154.1215 \t lr:0.000064\n","Train Epoch: 0 [2336/6456 (36%)]\ttrain_Loss: 1.77598 \tval_Loss: 0.00000 time: 156.2423 \t lr:0.000064\n","Train Epoch: 0 [2368/6456 (37%)]\ttrain_Loss: 1.88328 \tval_Loss: 0.00000 time: 158.3749 \t lr:0.000063\n","Train Epoch: 0 [2400/6456 (37%)]\ttrain_Loss: 1.87180 \tval_Loss: 0.00000 time: 160.4949 \t lr:0.000063\n","Train Epoch: 0 [2432/6456 (38%)]\ttrain_Loss: 1.82320 \tval_Loss: 0.00000 time: 162.6255 \t lr:0.000062\n","Train Epoch: 0 [2464/6456 (38%)]\ttrain_Loss: 1.83744 \tval_Loss: 0.00000 time: 164.7512 \t lr:0.000062\n","Train Epoch: 0 [2496/6456 (39%)]\ttrain_Loss: 1.81252 \tval_Loss: 0.00000 time: 166.8813 \t lr:0.000061\n","Train Epoch: 0 [2528/6456 (39%)]\ttrain_Loss: 1.81836 \tval_Loss: 0.00000 time: 169.0176 \t lr:0.000061\n","Train Epoch: 0 [2560/6456 (40%)]\ttrain_Loss: 1.85928 \tval_Loss: 0.00000 time: 171.1417 \t lr:0.000060\n","Train Epoch: 0 [2592/6456 (40%)]\ttrain_Loss: 1.82526 \tval_Loss: 0.00000 time: 173.2869 \t lr:0.000060\n","Train Epoch: 0 [2624/6456 (41%)]\ttrain_Loss: 1.82915 \tval_Loss: 0.00000 time: 175.4162 \t lr:0.000059\n","Train Epoch: 0 [2656/6456 (41%)]\ttrain_Loss: 1.82432 \tval_Loss: 0.00000 time: 177.5530 \t lr:0.000059\n","Train Epoch: 0 [2688/6456 (42%)]\ttrain_Loss: 1.84302 \tval_Loss: 0.00000 time: 179.6815 \t lr:0.000058\n","Train Epoch: 0 [2720/6456 (42%)]\ttrain_Loss: 1.83802 \tval_Loss: 0.00000 time: 181.8125 \t lr:0.000058\n","Train Epoch: 0 [2752/6456 (43%)]\ttrain_Loss: 1.78890 \tval_Loss: 0.00000 time: 183.9601 \t lr:0.000057\n","Train Epoch: 0 [2784/6456 (43%)]\ttrain_Loss: 1.84781 \tval_Loss: 0.00000 time: 186.0968 \t lr:0.000057\n","Train Epoch: 0 [2816/6456 (44%)]\ttrain_Loss: 1.77589 \tval_Loss: 0.00000 time: 188.2292 \t lr:0.000056\n","Train Epoch: 0 [2848/6456 (44%)]\ttrain_Loss: 1.79367 \tval_Loss: 0.00000 time: 190.3607 \t lr:0.000056\n","Train Epoch: 0 [2880/6456 (45%)]\ttrain_Loss: 1.79746 \tval_Loss: 0.00000 time: 192.4910 \t lr:0.000055\n","Train Epoch: 0 [2912/6456 (45%)]\ttrain_Loss: 1.78382 \tval_Loss: 0.00000 time: 194.6200 \t lr:0.000055\n","Train Epoch: 0 [2944/6456 (46%)]\ttrain_Loss: 1.75846 \tval_Loss: 0.00000 time: 196.7617 \t lr:0.000054\n","Train Epoch: 0 [2976/6456 (46%)]\ttrain_Loss: 1.86289 \tval_Loss: 0.00000 time: 198.8930 \t lr:0.000054\n","Train Epoch: 0 [3008/6456 (47%)]\ttrain_Loss: 1.78339 \tval_Loss: 0.00000 time: 201.0263 \t lr:0.000053\n","Train Epoch: 0 [3040/6456 (47%)]\ttrain_Loss: 1.81348 \tval_Loss: 0.00000 time: 203.1612 \t lr:0.000053\n","Train Epoch: 0 [3072/6456 (48%)]\ttrain_Loss: 1.75660 \tval_Loss: 0.00000 time: 205.2835 \t lr:0.000052\n","Train Epoch: 0 [3104/6456 (48%)]\ttrain_Loss: 1.77227 \tval_Loss: 0.00000 time: 207.4160 \t lr:0.000052\n","Train Epoch: 0 [3136/6456 (49%)]\ttrain_Loss: 1.80972 \tval_Loss: 0.00000 time: 209.5497 \t lr:0.000051\n","Train Epoch: 0 [3168/6456 (49%)]\ttrain_Loss: 1.80821 \tval_Loss: 0.00000 time: 211.6740 \t lr:0.000051\n","Train Epoch: 0 [3200/6456 (50%)]\ttrain_Loss: 1.79847 \tval_Loss: 0.00000 time: 213.8071 \t lr:0.000050\n","Train Epoch: 0 [3232/6456 (50%)]\ttrain_Loss: 1.78660 \tval_Loss: 0.00000 time: 215.9370 \t lr:0.000050\n","Train Epoch: 0 [3264/6456 (51%)]\ttrain_Loss: 1.79036 \tval_Loss: 0.00000 time: 218.0621 \t lr:0.000049\n","Train Epoch: 0 [3296/6456 (51%)]\ttrain_Loss: 1.78765 \tval_Loss: 0.00000 time: 220.1892 \t lr:0.000049\n","Train Epoch: 0 [3328/6456 (52%)]\ttrain_Loss: 1.82978 \tval_Loss: 0.00000 time: 222.3214 \t lr:0.000048\n","Train Epoch: 0 [3360/6456 (52%)]\ttrain_Loss: 1.81083 \tval_Loss: 0.00000 time: 224.4612 \t lr:0.000048\n","Train Epoch: 0 [3392/6456 (53%)]\ttrain_Loss: 1.82619 \tval_Loss: 0.00000 time: 226.6081 \t lr:0.000047\n","Train Epoch: 0 [3424/6456 (53%)]\ttrain_Loss: 1.78210 \tval_Loss: 0.00000 time: 228.7430 \t lr:0.000047\n","Train Epoch: 0 [3456/6456 (54%)]\ttrain_Loss: 1.80388 \tval_Loss: 0.00000 time: 230.8814 \t lr:0.000046\n","Train Epoch: 0 [3488/6456 (54%)]\ttrain_Loss: 1.83759 \tval_Loss: 0.00000 time: 233.0165 \t lr:0.000046\n","Train Epoch: 0 [3520/6456 (55%)]\ttrain_Loss: 1.78182 \tval_Loss: 0.00000 time: 235.1547 \t lr:0.000045\n","Train Epoch: 0 [3552/6456 (55%)]\ttrain_Loss: 1.83453 \tval_Loss: 0.00000 time: 237.2830 \t lr:0.000045\n","Train Epoch: 0 [3584/6456 (56%)]\ttrain_Loss: 1.81697 \tval_Loss: 0.00000 time: 239.4218 \t lr:0.000044\n","Train Epoch: 0 [3616/6456 (56%)]\ttrain_Loss: 1.81251 \tval_Loss: 0.00000 time: 241.5492 \t lr:0.000044\n","Train Epoch: 0 [3648/6456 (57%)]\ttrain_Loss: 1.81797 \tval_Loss: 0.00000 time: 243.6963 \t lr:0.000043\n","Train Epoch: 0 [3680/6456 (57%)]\ttrain_Loss: 1.83221 \tval_Loss: 0.00000 time: 245.8226 \t lr:0.000043\n","Train Epoch: 0 [3712/6456 (57%)]\ttrain_Loss: 1.83024 \tval_Loss: 0.00000 time: 247.9646 \t lr:0.000042\n","Train Epoch: 0 [3744/6456 (58%)]\ttrain_Loss: 1.83219 \tval_Loss: 0.00000 time: 250.0920 \t lr:0.000042\n","Train Epoch: 0 [3776/6456 (58%)]\ttrain_Loss: 1.75867 \tval_Loss: 0.00000 time: 252.2178 \t lr:0.000041\n","Train Epoch: 0 [3808/6456 (59%)]\ttrain_Loss: 1.84119 \tval_Loss: 0.00000 time: 254.3490 \t lr:0.000041\n","Train Epoch: 0 [3840/6456 (59%)]\ttrain_Loss: 1.84028 \tval_Loss: 0.00000 time: 256.4783 \t lr:0.000040\n","Train Epoch: 0 [3872/6456 (60%)]\ttrain_Loss: 1.72887 \tval_Loss: 0.00000 time: 258.6232 \t lr:0.000040\n","Train Epoch: 0 [3904/6456 (60%)]\ttrain_Loss: 1.85828 \tval_Loss: 0.00000 time: 260.7494 \t lr:0.000039\n","Train Epoch: 0 [3936/6456 (61%)]\ttrain_Loss: 1.79538 \tval_Loss: 0.00000 time: 262.8818 \t lr:0.000039\n","Train Epoch: 0 [3968/6456 (61%)]\ttrain_Loss: 1.87791 \tval_Loss: 0.00000 time: 265.0005 \t lr:0.000038\n","Train Epoch: 0 [4000/6456 (62%)]\ttrain_Loss: 1.81206 \tval_Loss: 0.00000 time: 267.1334 \t lr:0.000038\n","Train Epoch: 0 [4032/6456 (62%)]\ttrain_Loss: 1.83804 \tval_Loss: 0.00000 time: 269.2808 \t lr:0.000037\n","Train Epoch: 0 [4064/6456 (63%)]\ttrain_Loss: 1.80650 \tval_Loss: 0.00000 time: 271.4093 \t lr:0.000037\n","Train Epoch: 0 [4096/6456 (63%)]\ttrain_Loss: 1.77945 \tval_Loss: 0.00000 time: 273.5500 \t lr:0.000036\n","Train Epoch: 0 [4128/6456 (64%)]\ttrain_Loss: 1.83876 \tval_Loss: 0.00000 time: 275.6855 \t lr:0.000036\n","Train Epoch: 0 [4160/6456 (64%)]\ttrain_Loss: 1.80592 \tval_Loss: 0.00000 time: 277.8156 \t lr:0.000036\n","Train Epoch: 0 [4192/6456 (65%)]\ttrain_Loss: 1.78745 \tval_Loss: 0.00000 time: 279.9576 \t lr:0.000035\n","Train Epoch: 0 [4224/6456 (65%)]\ttrain_Loss: 1.80569 \tval_Loss: 0.00000 time: 282.0863 \t lr:0.000035\n","Train Epoch: 0 [4256/6456 (66%)]\ttrain_Loss: 1.82387 \tval_Loss: 0.00000 time: 284.2208 \t lr:0.000034\n","Train Epoch: 0 [4288/6456 (66%)]\ttrain_Loss: 1.83768 \tval_Loss: 0.00000 time: 286.3537 \t lr:0.000034\n","Train Epoch: 0 [4320/6456 (67%)]\ttrain_Loss: 1.82770 \tval_Loss: 0.00000 time: 288.4867 \t lr:0.000033\n","Train Epoch: 0 [4352/6456 (67%)]\ttrain_Loss: 1.82036 \tval_Loss: 0.00000 time: 290.6230 \t lr:0.000033\n","Train Epoch: 0 [4384/6456 (68%)]\ttrain_Loss: 1.79971 \tval_Loss: 0.00000 time: 292.7537 \t lr:0.000032\n","Train Epoch: 0 [4416/6456 (68%)]\ttrain_Loss: 1.84985 \tval_Loss: 0.00000 time: 294.8851 \t lr:0.000032\n","Train Epoch: 0 [4448/6456 (69%)]\ttrain_Loss: 1.79345 \tval_Loss: 0.00000 time: 297.0170 \t lr:0.000031\n","Train Epoch: 0 [4480/6456 (69%)]\ttrain_Loss: 1.85122 \tval_Loss: 0.00000 time: 299.1575 \t lr:0.000031\n","Train Epoch: 0 [4512/6456 (70%)]\ttrain_Loss: 1.76717 \tval_Loss: 0.00000 time: 301.2935 \t lr:0.000030\n","Train Epoch: 0 [4544/6456 (70%)]\ttrain_Loss: 1.74484 \tval_Loss: 0.00000 time: 303.4265 \t lr:0.000030\n","Train Epoch: 0 [4576/6456 (71%)]\ttrain_Loss: 1.82400 \tval_Loss: 0.00000 time: 305.5729 \t lr:0.000029\n","Train Epoch: 0 [4608/6456 (71%)]\ttrain_Loss: 1.80572 \tval_Loss: 0.00000 time: 307.6983 \t lr:0.000029\n","Train Epoch: 0 [4640/6456 (72%)]\ttrain_Loss: 1.84846 \tval_Loss: 0.00000 time: 309.8432 \t lr:0.000028\n","Train Epoch: 0 [4672/6456 (72%)]\ttrain_Loss: 1.76312 \tval_Loss: 0.00000 time: 311.9840 \t lr:0.000028\n","Train Epoch: 0 [4704/6456 (73%)]\ttrain_Loss: 1.75966 \tval_Loss: 0.00000 time: 314.1165 \t lr:0.000027\n","Train Epoch: 0 [4736/6456 (73%)]\ttrain_Loss: 1.78663 \tval_Loss: 0.00000 time: 316.2481 \t lr:0.000027\n","Train Epoch: 0 [4768/6456 (74%)]\ttrain_Loss: 1.83881 \tval_Loss: 0.00000 time: 318.3807 \t lr:0.000026\n","Train Epoch: 0 [4800/6456 (74%)]\ttrain_Loss: 1.82217 \tval_Loss: 0.00000 time: 320.5120 \t lr:0.000026\n","Train Epoch: 0 [4832/6456 (75%)]\ttrain_Loss: 1.74695 \tval_Loss: 0.00000 time: 322.6409 \t lr:0.000025\n","Train Epoch: 0 [4864/6456 (75%)]\ttrain_Loss: 1.82593 \tval_Loss: 0.00000 time: 324.7808 \t lr:0.000025\n","Train Epoch: 0 [4896/6456 (76%)]\ttrain_Loss: 1.82831 \tval_Loss: 0.00000 time: 326.9077 \t lr:0.000024\n","Train Epoch: 0 [4928/6456 (76%)]\ttrain_Loss: 1.80216 \tval_Loss: 0.00000 time: 329.0375 \t lr:0.000024\n","Train Epoch: 0 [4960/6456 (77%)]\ttrain_Loss: 1.78859 \tval_Loss: 0.00000 time: 331.1680 \t lr:0.000023\n","Train Epoch: 0 [4992/6456 (77%)]\ttrain_Loss: 1.77802 \tval_Loss: 0.00000 time: 333.2988 \t lr:0.000023\n","Train Epoch: 0 [5024/6456 (78%)]\ttrain_Loss: 1.81379 \tval_Loss: 0.00000 time: 335.4311 \t lr:0.000022\n","Train Epoch: 0 [5056/6456 (78%)]\ttrain_Loss: 1.75765 \tval_Loss: 0.00000 time: 337.5658 \t lr:0.000022\n","Train Epoch: 0 [5088/6456 (79%)]\ttrain_Loss: 1.87887 \tval_Loss: 0.00000 time: 339.6973 \t lr:0.000021\n","Train Epoch: 0 [5120/6456 (79%)]\ttrain_Loss: 1.86497 \tval_Loss: 0.00000 time: 341.8301 \t lr:0.000021\n","Train Epoch: 0 [5152/6456 (80%)]\ttrain_Loss: 1.83043 \tval_Loss: 0.00000 time: 343.9667 \t lr:0.000020\n","Train Epoch: 0 [5184/6456 (80%)]\ttrain_Loss: 1.80365 \tval_Loss: 0.00000 time: 346.0934 \t lr:0.000020\n","Train Epoch: 0 [5216/6456 (81%)]\ttrain_Loss: 1.83228 \tval_Loss: 0.00000 time: 348.2269 \t lr:0.000019\n","Train Epoch: 0 [5248/6456 (81%)]\ttrain_Loss: 1.83675 \tval_Loss: 0.00000 time: 350.3620 \t lr:0.000019\n","Train Epoch: 0 [5280/6456 (82%)]\ttrain_Loss: 1.72666 \tval_Loss: 0.00000 time: 352.5123 \t lr:0.000018\n","Train Epoch: 0 [5312/6456 (82%)]\ttrain_Loss: 1.77836 \tval_Loss: 0.00000 time: 354.6490 \t lr:0.000018\n","Train Epoch: 0 [5344/6456 (83%)]\ttrain_Loss: 1.83275 \tval_Loss: 0.00000 time: 356.7773 \t lr:0.000017\n","Train Epoch: 0 [5376/6456 (83%)]\ttrain_Loss: 1.85913 \tval_Loss: 0.00000 time: 358.9055 \t lr:0.000017\n","Train Epoch: 0 [5408/6456 (84%)]\ttrain_Loss: 1.82776 \tval_Loss: 0.00000 time: 361.0379 \t lr:0.000016\n","Train Epoch: 0 [5440/6456 (84%)]\ttrain_Loss: 1.75274 \tval_Loss: 0.00000 time: 363.1628 \t lr:0.000016\n","Train Epoch: 0 [5472/6456 (85%)]\ttrain_Loss: 1.88139 \tval_Loss: 0.00000 time: 365.2922 \t lr:0.000015\n","Train Epoch: 0 [5504/6456 (85%)]\ttrain_Loss: 1.83642 \tval_Loss: 0.00000 time: 367.4368 \t lr:0.000015\n","Train Epoch: 0 [5536/6456 (86%)]\ttrain_Loss: 1.80224 \tval_Loss: 0.00000 time: 369.5593 \t lr:0.000014\n","Train Epoch: 0 [5568/6456 (86%)]\ttrain_Loss: 1.77499 \tval_Loss: 0.00000 time: 371.6976 \t lr:0.000014\n","Train Epoch: 0 [5600/6456 (87%)]\ttrain_Loss: 1.79627 \tval_Loss: 0.00000 time: 373.8344 \t lr:0.000013\n","Train Epoch: 0 [5632/6456 (87%)]\ttrain_Loss: 1.82086 \tval_Loss: 0.00000 time: 375.9704 \t lr:0.000013\n","Train Epoch: 0 [5664/6456 (88%)]\ttrain_Loss: 1.84987 \tval_Loss: 0.00000 time: 378.1072 \t lr:0.000012\n","Train Epoch: 0 [5696/6456 (88%)]\ttrain_Loss: 1.80718 \tval_Loss: 0.00000 time: 380.2408 \t lr:0.000012\n","Train Epoch: 0 [5728/6456 (89%)]\ttrain_Loss: 1.80168 \tval_Loss: 0.00000 time: 382.3864 \t lr:0.000011\n","Train Epoch: 0 [5760/6456 (89%)]\ttrain_Loss: 1.79459 \tval_Loss: 0.00000 time: 384.5159 \t lr:0.000011\n","Train Epoch: 0 [5792/6456 (90%)]\ttrain_Loss: 1.84163 \tval_Loss: 0.00000 time: 386.6444 \t lr:0.000010\n","Train Epoch: 0 [5824/6456 (90%)]\ttrain_Loss: 1.75935 \tval_Loss: 0.00000 time: 388.7704 \t lr:0.000010\n","Train Epoch: 0 [5856/6456 (91%)]\ttrain_Loss: 1.83178 \tval_Loss: 0.00000 time: 390.9041 \t lr:0.000009\n","Train Epoch: 0 [5888/6456 (91%)]\ttrain_Loss: 1.81492 \tval_Loss: 0.00000 time: 393.0329 \t lr:0.000009\n","Train Epoch: 0 [5920/6456 (92%)]\ttrain_Loss: 1.75274 \tval_Loss: 0.00000 time: 395.1754 \t lr:0.000008\n","Train Epoch: 0 [5952/6456 (92%)]\ttrain_Loss: 1.77130 \tval_Loss: 0.00000 time: 397.3145 \t lr:0.000008\n","Train Epoch: 0 [5984/6456 (93%)]\ttrain_Loss: 1.79043 \tval_Loss: 0.00000 time: 399.4571 \t lr:0.000007\n","Train Epoch: 0 [6016/6456 (93%)]\ttrain_Loss: 1.77761 \tval_Loss: 0.00000 time: 401.5841 \t lr:0.000007\n","Train Epoch: 0 [6048/6456 (94%)]\ttrain_Loss: 1.79025 \tval_Loss: 0.00000 time: 403.7055 \t lr:0.000006\n","Train Epoch: 0 [6080/6456 (94%)]\ttrain_Loss: 1.79665 \tval_Loss: 0.00000 time: 405.8407 \t lr:0.000006\n","Train Epoch: 0 [6112/6456 (95%)]\ttrain_Loss: 1.79770 \tval_Loss: 0.00000 time: 407.9654 \t lr:0.000005\n","Train Epoch: 0 [6144/6456 (95%)]\ttrain_Loss: 1.79606 \tval_Loss: 0.00000 time: 410.0922 \t lr:0.000005\n","Train Epoch: 0 [6176/6456 (96%)]\ttrain_Loss: 1.84528 \tval_Loss: 0.00000 time: 412.2194 \t lr:0.000004\n","Train Epoch: 0 [6208/6456 (96%)]\ttrain_Loss: 1.83750 \tval_Loss: 0.00000 time: 414.3530 \t lr:0.000004\n","Train Epoch: 0 [6240/6456 (97%)]\ttrain_Loss: 1.73708 \tval_Loss: 0.00000 time: 416.4970 \t lr:0.000003\n","Train Epoch: 0 [6272/6456 (97%)]\ttrain_Loss: 1.72629 \tval_Loss: 0.00000 time: 418.6292 \t lr:0.000003\n","Train Epoch: 0 [6304/6456 (98%)]\ttrain_Loss: 1.76526 \tval_Loss: 0.00000 time: 420.7586 \t lr:0.000002\n","Train Epoch: 0 [6336/6456 (98%)]\ttrain_Loss: 1.80966 \tval_Loss: 0.00000 time: 422.8890 \t lr:0.000002\n","Train Epoch: 0 [6368/6456 (99%)]\ttrain_Loss: 1.84420 \tval_Loss: 0.00000 time: 425.0285 \t lr:0.000001\n","Train Epoch: 0 [6400/6456 (99%)]\ttrain_Loss: 1.80854 \tval_Loss: 0.00000 time: 427.1579 \t lr:0.000001\n","Train Epoch: 0 [6432/6456 (100%)]\ttrain_Loss: 1.82912 \tval_Loss: 0.00000 time: 429.2924 \t lr:0.000000\n","Val_loss: tensor(7.3674, device='cuda:0')\n","update!!!!!!!!!!!!\n"]}]},{"cell_type":"code","source":["!python /content/drive/MyDrive/GitHub/exBERT/Finetuning_NER.py -e 1 -b 2 -sp /content/drive/MyDrive/GitHub/exBERT/PubMED_train_files/PubMed_output -dv 0 -lr 1e-04 -str exBERT -config /content/drive/MyDrive/GitHub/exBERT/pretrained_files/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12/config.json /content/drive/MyDrive/GitHub/exBERT/output/bert_config_ex_base_s3.json -vocab /content/drive/MyDrive/GitHub/exBERT/output/overall_voc.txt -pm_p /content/drive/MyDrive/GitHub/exBERT/pretrained_files/NCBI_BERT_pubmed_mimic_uncased_L-24_H-1024_A-16_torch/pytorch_model.bin -dp /content/drive/MyDrive/GitHub/exBERT/ner_sample_data/ -tln 24\n"],"metadata":{"id":"9ZAnqpHbQaM2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"dCe0W-t_QfOP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"s9jGr4txQfL5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"nEom5bNFQfJQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"VD2n3uYjQfGs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python bert/create_pretraining_data.py --input_file=/content/drive/MyDrive/GitHub/exBERT/data/train_data.txt --output_file=/content/drive/MyDrive/GitHub/exBERT/PubMED_train_files/pubmed_uncased_train_data.tfrecord --vocab_file=/content/drive/MyDrive/GitHub/exBERT/PubMED_train_files/PubMed/vocab.txt --do_lower_case=True --max_seq_length=512 --max_predictions_per_seq=20 --masked_lm_prob=0.15 --random_seed=12345 --dupe_factor=5\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QRRdhPogFJ1k","executionInfo":{"status":"ok","timestamp":1648448166129,"user_tz":-60,"elapsed":2506,"user":{"displayName":"Lya Solis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0zQkkPA02m_TCbUFh15I5DgeImYkaFOwSePgp=s64","userId":"00474828135331575492"}},"outputId":"1e6cfe65-dbcc-48e4-ff3b-0e2e72a62569"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"bert/create_pretraining_data.py\", line 24, in <module>\n","    from bert import tokenization\n","ModuleNotFoundError: No module named 'bert'\n"]}]},{"cell_type":"markdown","source":["https://medium.com/@manasmohanty/ncbi-bluebert-ncbi-bert-using-tensorflow-weights-with-huggingface-transformers-15a7ec27fc3d"],"metadata":{"id":"vNLx5UHkEk_Z"}},{"cell_type":"markdown","source":["We used the following code to train the BERT model. Please do not include init_checkpoint if you are pre-training from scratch. Please see https://github.com/google-research/bert for more details."],"metadata":{"id":"nMr5OpPvhSVk"}},{"cell_type":"code","source":["python bert/run_pretraining.py \\\n","  --input_file=pubmed_uncased_sentence_nltk.tfrecord \\\n","  --output_dir=$BlueBERT_DIR \\\n","  --do_train=True \\\n","  --do_eval=True \\\n","  --bert_config_file=$BlueBERT_DIR/bert_config.json \\\n","  --init_checkpoint=$BlueBERT_DIR/bert_model.ckpt \\\n","  --train_batch_size=32 \\\n","  --max_seq_length=128 \\\n","  --max_predictions_per_seq=20 \\\n","  --num_train_steps=20000 \\\n","  --num_warmup_steps=10 \\\n","  --learning_rate=2e-5"],"metadata":{"id":"vUw5WewxgzNg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"CWX4y94ygzQX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"sdFEO9-igzVm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"iPXY_Jz6gzYt"},"execution_count":null,"outputs":[]}]}